{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3400fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!sudo /opt/conda/bin/conda install conda-build -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32980464",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T15:53:19.909394Z",
     "start_time": "2024-11-18T15:53:18.779242Z"
    }
   },
   "outputs": [],
   "source": [
    "#!sudo /opt/conda/bin/conda-develop -n QML-QPF PATH /workspaces/QML-QPF/mosaiQue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd08081e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 16:39:04.685550: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-25 16:39:05.423622: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "import mosaique as mq\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from tensorflow import keras\n",
    "from mosaique.models.operation import OperationLayer\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "\n",
    "cifar_dataset = keras.datasets.cifar10\n",
    "train_layer = mq.ConvolutionLayer4x4(\"cifar_train\")\n",
    "test_layer = mq.ConvolutionLayer4x4(\"cifar_test\")\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar_dataset.load_data()\n",
    "train_layer.fit(train_images)\n",
    "test_layer.fit(test_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3585c58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def model(variant, tr_layer, te_layer):\n",
    "    tr_images = tr_layer.open(variant)\n",
    "    te_images =  te_layer.open(variant)\n",
    "\n",
    "    log_dir = tr_layer.name + \"/run1/\" + ''.join(map(str,variant))\n",
    "\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        histogram_freq=1,\n",
    "        write_graph=True,\n",
    "        write_images=True,\n",
    "        write_steps_per_second=True,\n",
    "        update_freq='batch',\n",
    "        profile_batch=1,\n",
    "        embeddings_freq=1,\n",
    "        embeddings_metadata=None\n",
    "    )\n",
    "    q_model = keras.models.Sequential([\n",
    "        keras.layers.Rescaling(scale=-1. / 127.5, offset=1),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "    q_model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    q_history = q_model.fit(\n",
    "        tr_images,\n",
    "        train_labels,\n",
    "        validation_data=(te_images, test_labels),\n",
    "        batch_size=128,\n",
    "        epochs=30,\n",
    "        verbose=2,\n",
    "        callbacks=[tensorboard_callback]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae457a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "permutations = np.asarray(list(itertools.permutations(range(4))))\n",
    "\n",
    "#[model(variant = p, tr_layer = train_layer, te_layer= test_layer) for p in permutations[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d559b4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 16, 16, 4)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "print(train_layer.open([0,1,2,3]).shape)\n",
    "\n",
    "post = train_layer.open([0,1,2,3])\n",
    "\n",
    "_min, _max = np.amin(post), np.amax(post)\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "# Plot all output channels for quantum cnot\n",
    "for c in range(4):\n",
    "    axes[c].imshow(post[0,:,:,c],vmin = _min, vmax = _max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b3224d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x77bd31deb520>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((train_layer.channel_merge(post))[0,:,:],vmin = _min, vmax = _max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f3cc1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 16:39:08.705428: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:39:08.705530: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:39:08.709374: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:39:08.709376: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:39:08.709453: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:39:08.709455: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:39:08.712613: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:39:08.712682: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:39:08.727809: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-11-25 16:39:08.728074: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-11-25 16:39:08.728195: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-11-25 16:39:08.728531: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-11-25 16:39:08.746398: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:39:08.746525: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:39:08.748921: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:39:08.749062: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:39:08.749038: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:39:08.749038: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:39:08.749101: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:39:08.749101: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:39:08.751184: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:39:08.751184: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:39:08.751323: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:39:08.751365: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:39:08.751690: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:39:08.751758: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:39:08.752940: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:39:08.753006: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:39:08.760325: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-11-25 16:39:08.760528: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-11-25 16:39:08.763559: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-11-25 16:39:08.764254: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-11-25 16:39:08.778104: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:39:08.778236: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:39:08.782071: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:39:08.782199: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:39:08.783740: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:39:08.783741: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:39:08.783896: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:39:08.783906: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:39:09.161580: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-11-25 16:39:09.168397: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-11-25 16:39:09.168397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6609 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-11-25 16:39:09.170582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6603 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-11-25 16:39:09.209011: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-11-25 16:39:09.209334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6177 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-11-25 16:39:09.211524: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-11-25 16:39:09.211867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6177 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-11-25 16:39:09.212713: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-11-25 16:39:09.213134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6177 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-11-25 16:39:09.225763: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-11-25 16:39:09.226133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5961 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-11-25 16:39:09.234829: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-11-25 16:39:09.235344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5961 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-11-25 16:39:09.243031: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-11-25 16:39:09.243556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6177 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "Epoch 1/30\n",
      "Epoch 1/30\n",
      "Epoch 1/30\n",
      "Epoch 1/30\n",
      "Epoch 1/30\n",
      "Epoch 1/30\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 16:39:10.235123: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:39:10.235182: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:39:10.276497: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:39:10.276551: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:39:10.310292: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:39:10.310435: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:39:10.330630: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:39:10.330773: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:39:10.348557: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:39:10.348671: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:39:10.372854: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:39:10.372986: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:39:10.384538: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:39:10.384655: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:39:10.395844: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:39:10.395983: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732552750.719264  692700 service.cc:145] XLA service 0x77bc5801b0f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732552750.719311  692700 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-11-25 16:39:10.738515: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732552750.773204  692685 service.cc:145] XLA service 0x77bc64034070 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732552750.773255  692685 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732552750.773689  692671 service.cc:145] XLA service 0x77bc640193c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732552750.773734  692671 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732552750.777196  692641 service.cc:145] XLA service 0x77bc64017e50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732552750.777239  692641 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-11-25 16:39:10.792319: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-25 16:39:10.794193: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-25 16:39:10.795333: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732552750.804215  692654 service.cc:145] XLA service 0x77bc60019de0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732552750.804271  692654 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-11-25 16:39:10.807123: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732552750.814836  692713 service.cc:145] XLA service 0x77bc5c0194d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732552750.814894  692713 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-11-25 16:39:10.827171: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-25 16:39:10.835281: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-25 16:39:10.853666: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-11-25 16:39:10.854705: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-11-25 16:39:10.869309: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-11-25 16:39:10.881589: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732552750.904665  692741 service.cc:145] XLA service 0x77bc58032450 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732552750.904715  692741 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-11-25 16:39:10.919945: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-11-25 16:39:10.924481: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732552750.953885  692726 service.cc:145] XLA service 0x77bc60017e60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732552750.953935  692726 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-11-25 16:39:10.971004: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-25 16:39:10.983378: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-11-25 16:39:11.040064: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "I0000 00:00:1732552751.135029  692700 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-11-25 16:39:11.218179: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-11-25 16:39:11.220146: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:39:11.229512: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:540]  GpuTracer has collected 2000 callback api events and 1648 activity events. \n",
      "2024-11-25 16:39:11.241736: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:39:11.242640: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: cifar_train/run1/0132/plugins/profile/2024_11_25_16_39_11/3a9247a29c0e.xplane.pb\n",
      "I0000 00:00:1732552751.454297  692685 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1732552751.456307  692641 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-11-25 16:39:11.534492: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-11-25 16:39:11.536743: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:39:11.536791: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-11-25 16:39:11.539637: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:39:11.545414: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:540]  GpuTracer has collected 1998 callback api events and 1647 activity events. \n",
      "I0000 00:00:1732552751.549028  692654 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1732552751.549026  692671 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-11-25 16:39:11.551351: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:540]  GpuTracer has collected 1998 callback api events and 1647 activity events. \n",
      "I0000 00:00:1732552751.551964  692713 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-11-25 16:39:11.557784: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:39:11.558831: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: cifar_train/run1/0213/plugins/profile/2024_11_25_16_39_11/3a9247a29c0e.xplane.pb\n",
      "2024-11-25 16:39:11.565463: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:39:11.566802: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: cifar_train/run1/0312/plugins/profile/2024_11_25_16_39_11/3a9247a29c0e.xplane.pb\n",
      "I0000 00:00:1732552751.576361  692741 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1732552751.587877  692726 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-11-25 16:39:11.636709: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-11-25 16:39:11.637028: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-11-25 16:39:11.638901: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:39:11.639226: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:39:11.640935: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-11-25 16:39:11.643197: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:39:11.648321: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:540]  GpuTracer has collected 1998 callback api events and 1647 activity events. \n",
      "2024-11-25 16:39:11.648321: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:540]  GpuTracer has collected 1998 callback api events and 1647 activity events. \n",
      "2024-11-25 16:39:11.652614: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:540]  GpuTracer has collected 1998 callback api events and 1647 activity events. \n",
      "2024-11-25 16:39:11.663927: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:39:11.664361: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:39:11.665386: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: cifar_train/run1/0321/plugins/profile/2024_11_25_16_39_11/3a9247a29c0e.xplane.pb\n",
      "2024-11-25 16:39:11.665901: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: cifar_train/run1/1023/plugins/profile/2024_11_25_16_39_11/3a9247a29c0e.xplane.pb\n",
      "2024-11-25 16:39:11.666188: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-11-25 16:39:11.668308: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:39:11.668608: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:39:11.670155: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: cifar_train/run1/0231/plugins/profile/2024_11_25_16_39_11/3a9247a29c0e.xplane.pb\n",
      "2024-11-25 16:39:11.677972: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:540]  GpuTracer has collected 1998 callback api events and 1647 activity events. \n",
      "2024-11-25 16:39:11.681592: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-11-25 16:39:11.683877: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:39:11.693144: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:39:11.693722: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:540]  GpuTracer has collected 1998 callback api events and 1647 activity events. \n",
      "2024-11-25 16:39:11.694645: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: cifar_train/run1/1032/plugins/profile/2024_11_25_16_39_11/3a9247a29c0e.xplane.pb\n",
      "2024-11-25 16:39:11.707617: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:39:11.709042: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: cifar_train/run1/0123/plugins/profile/2024_11_25_16_39_11/3a9247a29c0e.xplane.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 - 5s - 12ms/step - accuracy: 0.2819 - loss: 2.0442 - val_accuracy: 0.3060 - val_loss: 1.9887\n",
      "Epoch 2/30\n",
      "391/391 - 5s - 13ms/step - accuracy: 0.2799 - loss: 2.0381 - val_accuracy: 0.3131 - val_loss: 1.9753\n",
      "391/391 - 5s - 13ms/step - accuracy: 0.2810 - loss: 2.0355 - val_accuracy: 0.3095 - val_loss: 1.9794\n",
      "Epoch 2/30\n",
      "Epoch 2/30\n",
      "391/391 - 5s - 14ms/step - accuracy: 0.2798 - loss: 2.0388 - val_accuracy: 0.3172 - val_loss: 1.9731\n",
      "Epoch 2/30\n",
      "391/391 - 6s - 14ms/step - accuracy: 0.2803 - loss: 2.0420 - val_accuracy: 0.3078 - val_loss: 1.9815\n",
      "Epoch 2/30\n",
      "391/391 - 5s - 14ms/step - accuracy: 0.2807 - loss: 2.0448 - val_accuracy: 0.3074 - val_loss: 1.9879\n",
      "Epoch 2/30\n",
      "391/391 - 5s - 14ms/step - accuracy: 0.2779 - loss: 2.0473 - val_accuracy: 0.3008 - val_loss: 1.9926\n",
      "391/391 - 5s - 14ms/step - accuracy: 0.2856 - loss: 2.0376 - val_accuracy: 0.3086 - val_loss: 1.9799\n",
      "Epoch 2/30\n",
      "Epoch 2/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3144 - loss: 1.9660 - val_accuracy: 0.3181 - val_loss: 1.9653\n",
      "Epoch 3/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3138 - loss: 1.9623 - val_accuracy: 0.3203 - val_loss: 1.9670\n",
      "Epoch 3/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3200 - loss: 1.9492 - val_accuracy: 0.3308 - val_loss: 1.9431\n",
      "Epoch 3/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3196 - loss: 1.9504 - val_accuracy: 0.3248 - val_loss: 1.9556\n",
      "Epoch 3/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3125 - loss: 1.9684 - val_accuracy: 0.3175 - val_loss: 1.9693\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3157 - loss: 1.9659 - val_accuracy: 0.3134 - val_loss: 1.9725\n",
      "Epoch 3/30\n",
      "Epoch 3/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3145 - loss: 1.9611 - val_accuracy: 0.3220 - val_loss: 1.9605\n",
      "Epoch 3/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3136 - loss: 1.9676 - val_accuracy: 0.3171 - val_loss: 1.9708\n",
      "Epoch 3/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3248 - loss: 1.9423 - val_accuracy: 0.3248 - val_loss: 1.9693\n",
      "Epoch 4/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3256 - loss: 1.9396 - val_accuracy: 0.3229 - val_loss: 1.9571\n",
      "Epoch 4/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3328 - loss: 1.9175 - val_accuracy: 0.3304 - val_loss: 1.9434\n",
      "Epoch 4/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3317 - loss: 1.9178 - val_accuracy: 0.3324 - val_loss: 1.9362\n",
      "Epoch 4/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3257 - loss: 1.9415 - val_accuracy: 0.3207 - val_loss: 1.9636\n",
      "Epoch 4/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3246 - loss: 1.9371 - val_accuracy: 0.3241 - val_loss: 1.9524\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3253 - loss: 1.9431 - val_accuracy: 0.3181 - val_loss: 1.9756\n",
      "Epoch 4/30\n",
      "Epoch 4/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3238 - loss: 1.9447 - val_accuracy: 0.3116 - val_loss: 1.9809\n",
      "Epoch 4/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3321 - loss: 1.9245 - val_accuracy: 0.3184 - val_loss: 1.9667\n",
      "Epoch 5/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3322 - loss: 1.9235 - val_accuracy: 0.3183 - val_loss: 1.9518\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3411 - loss: 1.8969 - val_accuracy: 0.3364 - val_loss: 1.9266\n",
      "Epoch 5/30\n",
      "Epoch 5/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3424 - loss: 1.8960 - val_accuracy: 0.3334 - val_loss: 1.9286\n",
      "Epoch 5/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3350 - loss: 1.9210 - val_accuracy: 0.3127 - val_loss: 1.9698\n",
      "Epoch 5/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3311 - loss: 1.9308 - val_accuracy: 0.3156 - val_loss: 1.9623\n",
      "Epoch 5/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3285 - loss: 1.9308 - val_accuracy: 0.3225 - val_loss: 1.9630\n",
      "Epoch 5/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3359 - loss: 1.9149 - val_accuracy: 0.3198 - val_loss: 1.9588\n",
      "Epoch 6/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3372 - loss: 1.9126 - val_accuracy: 0.3233 - val_loss: 1.9476\n",
      "Epoch 6/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3479 - loss: 1.8799 - val_accuracy: 0.3339 - val_loss: 1.9306\n",
      "Epoch 6/30\n",
      "391/391 - 5s - 13ms/step - accuracy: 0.3318 - loss: 1.9261 - val_accuracy: 0.3228 - val_loss: 1.9610\n",
      "Epoch 5/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3494 - loss: 1.8784 - val_accuracy: 0.3355 - val_loss: 1.9312\n",
      "Epoch 6/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3364 - loss: 1.9089 - val_accuracy: 0.3227 - val_loss: 1.9501\n",
      "Epoch 6/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3364 - loss: 1.9187 - val_accuracy: 0.3173 - val_loss: 1.9614\n",
      "Epoch 6/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3334 - loss: 1.9178 - val_accuracy: 0.3231 - val_loss: 1.9661\n",
      "Epoch 6/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3389 - loss: 1.9062 - val_accuracy: 0.3158 - val_loss: 1.9659\n",
      "Epoch 7/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3378 - loss: 1.9058 - val_accuracy: 0.3100 - val_loss: 1.9660\n",
      "Epoch 7/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3552 - loss: 1.8652 - val_accuracy: 0.3261 - val_loss: 1.9201\n",
      "Epoch 7/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3527 - loss: 1.8661 - val_accuracy: 0.3364 - val_loss: 1.9094\n",
      "Epoch 7/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3375 - loss: 1.9133 - val_accuracy: 0.3215 - val_loss: 1.9541\n",
      "Epoch 6/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3394 - loss: 1.9124 - val_accuracy: 0.3207 - val_loss: 1.9596\n",
      "Epoch 7/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3408 - loss: 1.9008 - val_accuracy: 0.3189 - val_loss: 1.9516\n",
      "Epoch 7/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3362 - loss: 1.9122 - val_accuracy: 0.3226 - val_loss: 1.9563\n",
      "Epoch 7/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3419 - loss: 1.8992 - val_accuracy: 0.3277 - val_loss: 1.9585\n",
      "Epoch 8/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3410 - loss: 1.8993 - val_accuracy: 0.3171 - val_loss: 1.9566\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3583 - loss: 1.8519 - val_accuracy: 0.3366 - val_loss: 1.9118\n",
      "Epoch 8/30\n",
      "Epoch 8/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3394 - loss: 1.9069 - val_accuracy: 0.3090 - val_loss: 1.9770\n",
      "Epoch 7/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3417 - loss: 1.9044 - val_accuracy: 0.3108 - val_loss: 1.9686\n",
      "Epoch 8/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3433 - loss: 1.8934 - val_accuracy: 0.3255 - val_loss: 1.9475\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3385 - loss: 1.9066 - val_accuracy: 0.3184 - val_loss: 1.9591\n",
      "Epoch 8/30\n",
      "Epoch 8/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3449 - loss: 1.8958 - val_accuracy: 0.3141 - val_loss: 1.9694\n",
      "Epoch 9/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3402 - loss: 1.8955 - val_accuracy: 0.3190 - val_loss: 1.9665\n",
      "Epoch 9/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3624 - loss: 1.8420 - val_accuracy: 0.3335 - val_loss: 1.9070\n",
      "Epoch 9/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3424 - loss: 1.9005 - val_accuracy: 0.3216 - val_loss: 1.9662\n",
      "Epoch 8/30\n",
      "391/391 - 5s - 13ms/step - accuracy: 0.3574 - loss: 1.8541 - val_accuracy: 0.3401 - val_loss: 1.9056\n",
      "Epoch 8/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3416 - loss: 1.9018 - val_accuracy: 0.3223 - val_loss: 1.9571\n",
      "Epoch 9/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3433 - loss: 1.8992 - val_accuracy: 0.3165 - val_loss: 1.9610\n",
      "Epoch 9/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3457 - loss: 1.8875 - val_accuracy: 0.3311 - val_loss: 1.9467\n",
      "Epoch 9/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3462 - loss: 1.8903 - val_accuracy: 0.3187 - val_loss: 1.9719\n",
      "Epoch 10/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3624 - loss: 1.8354 - val_accuracy: 0.3468 - val_loss: 1.9007\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3454 - loss: 1.8902 - val_accuracy: 0.3175 - val_loss: 1.9518\n",
      "Epoch 10/30\n",
      "Epoch 10/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3442 - loss: 1.8951 - val_accuracy: 0.3207 - val_loss: 1.9658\n",
      "Epoch 9/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3648 - loss: 1.8426 - val_accuracy: 0.3479 - val_loss: 1.9012\n",
      "Epoch 9/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3412 - loss: 1.8986 - val_accuracy: 0.3199 - val_loss: 1.9575\n",
      "Epoch 10/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3476 - loss: 1.8814 - val_accuracy: 0.3216 - val_loss: 1.9528\n",
      "Epoch 10/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3436 - loss: 1.8955 - val_accuracy: 0.3194 - val_loss: 1.9649\n",
      "Epoch 10/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3489 - loss: 1.8857 - val_accuracy: 0.3253 - val_loss: 1.9584\n",
      "Epoch 11/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3457 - loss: 1.8858 - val_accuracy: 0.3077 - val_loss: 1.9715\n",
      "Epoch 11/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3673 - loss: 1.8268 - val_accuracy: 0.3421 - val_loss: 1.8930\n",
      "Epoch 11/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3444 - loss: 1.8901 - val_accuracy: 0.3233 - val_loss: 1.9527\n",
      "Epoch 10/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3660 - loss: 1.8340 - val_accuracy: 0.3424 - val_loss: 1.8977\n",
      "Epoch 10/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3446 - loss: 1.8929 - val_accuracy: 0.3258 - val_loss: 1.9562\n",
      "Epoch 11/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3492 - loss: 1.8796 - val_accuracy: 0.3201 - val_loss: 1.9501\n",
      "Epoch 11/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3444 - loss: 1.8930 - val_accuracy: 0.3200 - val_loss: 1.9608\n",
      "Epoch 11/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3485 - loss: 1.8851 - val_accuracy: 0.3157 - val_loss: 1.9590\n",
      "Epoch 12/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3492 - loss: 1.8835 - val_accuracy: 0.3150 - val_loss: 1.9588\n",
      "Epoch 12/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3696 - loss: 1.8204 - val_accuracy: 0.3458 - val_loss: 1.8893\n",
      "Epoch 12/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3484 - loss: 1.8849 - val_accuracy: 0.3269 - val_loss: 1.9551\n",
      "Epoch 11/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3679 - loss: 1.8255 - val_accuracy: 0.3473 - val_loss: 1.8897\n",
      "Epoch 11/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3458 - loss: 1.8887 - val_accuracy: 0.3263 - val_loss: 1.9573\n",
      "Epoch 12/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3544 - loss: 1.8731 - val_accuracy: 0.3220 - val_loss: 1.9498\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3428 - loss: 1.8903 - val_accuracy: 0.3197 - val_loss: 1.9719\n",
      "Epoch 12/30\n",
      "Epoch 12/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3511 - loss: 1.8799 - val_accuracy: 0.3195 - val_loss: 1.9700\n",
      "Epoch 13/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3496 - loss: 1.8792 - val_accuracy: 0.3157 - val_loss: 1.9585\n",
      "Epoch 13/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3717 - loss: 1.8147 - val_accuracy: 0.3466 - val_loss: 1.8884\n",
      "Epoch 13/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3714 - loss: 1.8197 - val_accuracy: 0.3434 - val_loss: 1.8927\n",
      "Epoch 12/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3494 - loss: 1.8826 - val_accuracy: 0.3227 - val_loss: 1.9546\n",
      "Epoch 12/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3467 - loss: 1.8877 - val_accuracy: 0.3152 - val_loss: 1.9646\n",
      "Epoch 13/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3501 - loss: 1.8730 - val_accuracy: 0.3218 - val_loss: 1.9535\n",
      "Epoch 13/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3451 - loss: 1.8877 - val_accuracy: 0.3128 - val_loss: 1.9774\n",
      "Epoch 13/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3499 - loss: 1.8781 - val_accuracy: 0.3231 - val_loss: 1.9658\n",
      "Epoch 14/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3494 - loss: 1.8770 - val_accuracy: 0.3185 - val_loss: 1.9609\n",
      "Epoch 14/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3758 - loss: 1.8065 - val_accuracy: 0.3437 - val_loss: 1.9010\n",
      "Epoch 14/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3514 - loss: 1.8797 - val_accuracy: 0.3185 - val_loss: 1.9655\n",
      "Epoch 13/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3747 - loss: 1.8135 - val_accuracy: 0.3468 - val_loss: 1.8962\n",
      "Epoch 13/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3463 - loss: 1.8875 - val_accuracy: 0.3156 - val_loss: 1.9721\n",
      "Epoch 14/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3555 - loss: 1.8687 - val_accuracy: 0.3164 - val_loss: 1.9503\n",
      "Epoch 14/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3459 - loss: 1.8830 - val_accuracy: 0.3195 - val_loss: 1.9652\n",
      "Epoch 14/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3516 - loss: 1.8778 - val_accuracy: 0.3161 - val_loss: 1.9642\n",
      "Epoch 15/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3513 - loss: 1.8775 - val_accuracy: 0.3173 - val_loss: 1.9505\n",
      "Epoch 15/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3739 - loss: 1.8039 - val_accuracy: 0.3512 - val_loss: 1.8807\n",
      "Epoch 15/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3491 - loss: 1.8765 - val_accuracy: 0.3153 - val_loss: 1.9660\n",
      "Epoch 14/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3468 - loss: 1.8834 - val_accuracy: 0.3167 - val_loss: 1.9686\n",
      "Epoch 15/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3765 - loss: 1.8066 - val_accuracy: 0.3493 - val_loss: 1.8832\n",
      "Epoch 14/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3524 - loss: 1.8685 - val_accuracy: 0.3163 - val_loss: 1.9553\n",
      "Epoch 15/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3483 - loss: 1.8831 - val_accuracy: 0.3143 - val_loss: 1.9697\n",
      "Epoch 15/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3506 - loss: 1.8754 - val_accuracy: 0.3150 - val_loss: 1.9681\n",
      "Epoch 16/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3782 - loss: 1.7990 - val_accuracy: 0.3512 - val_loss: 1.8762\n",
      "Epoch 16/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3511 - loss: 1.8728 - val_accuracy: 0.3237 - val_loss: 1.9501\n",
      "Epoch 16/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3518 - loss: 1.8738 - val_accuracy: 0.3184 - val_loss: 1.9645\n",
      "Epoch 15/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3752 - loss: 1.8048 - val_accuracy: 0.3462 - val_loss: 1.8838\n",
      "Epoch 15/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3485 - loss: 1.8819 - val_accuracy: 0.3196 - val_loss: 1.9766\n",
      "Epoch 16/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3528 - loss: 1.8658 - val_accuracy: 0.3157 - val_loss: 1.9555\n",
      "Epoch 16/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3462 - loss: 1.8822 - val_accuracy: 0.3215 - val_loss: 1.9636\n",
      "Epoch 16/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3512 - loss: 1.8728 - val_accuracy: 0.3161 - val_loss: 1.9642\n",
      "Epoch 17/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3777 - loss: 1.7962 - val_accuracy: 0.3446 - val_loss: 1.8822\n",
      "Epoch 17/30\n",
      "391/391 - 2s - 5ms/step - accuracy: 0.3786 - loss: 1.7974 - val_accuracy: 0.3432 - val_loss: 1.8925\n",
      "Epoch 16/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3503 - loss: 1.8803 - val_accuracy: 0.3048 - val_loss: 1.9819\n",
      "Epoch 17/30\n",
      "391/391 - 2s - 5ms/step - accuracy: 0.3552 - loss: 1.8635 - val_accuracy: 0.3203 - val_loss: 1.9562\n",
      "Epoch 17/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3522 - loss: 1.8719 - val_accuracy: 0.3121 - val_loss: 1.9842\n",
      "Epoch 18/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3816 - loss: 1.7908 - val_accuracy: 0.3505 - val_loss: 1.8776\n",
      "Epoch 18/30\n",
      "391/391 - 5s - 12ms/step - accuracy: 0.3507 - loss: 1.8730 - val_accuracy: 0.3163 - val_loss: 1.9597\n",
      "Epoch 17/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3797 - loss: 1.7949 - val_accuracy: 0.3513 - val_loss: 1.8773\n",
      "Epoch 17/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3501 - loss: 1.8810 - val_accuracy: 0.3171 - val_loss: 1.9691\n",
      "Epoch 18/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3527 - loss: 1.8627 - val_accuracy: 0.3128 - val_loss: 1.9581\n",
      "Epoch 18/30\n",
      "391/391 - 5s - 13ms/step - accuracy: 0.3512 - loss: 1.8722 - val_accuracy: 0.3214 - val_loss: 1.9695\n",
      "Epoch 16/30\n",
      "391/391 - 5s - 13ms/step - accuracy: 0.3478 - loss: 1.8795 - val_accuracy: 0.3254 - val_loss: 1.9737\n",
      "Epoch 17/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3527 - loss: 1.8702 - val_accuracy: 0.3151 - val_loss: 1.9735\n",
      "Epoch 19/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3821 - loss: 1.7887 - val_accuracy: 0.3509 - val_loss: 1.8746\n",
      "Epoch 19/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3520 - loss: 1.8714 - val_accuracy: 0.3170 - val_loss: 1.9601\n",
      "Epoch 18/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3832 - loss: 1.7879 - val_accuracy: 0.3465 - val_loss: 1.8849\n",
      "Epoch 18/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3510 - loss: 1.8776 - val_accuracy: 0.3158 - val_loss: 1.9766\n",
      "Epoch 19/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3559 - loss: 1.8606 - val_accuracy: 0.3199 - val_loss: 1.9673\n",
      "Epoch 19/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3518 - loss: 1.8719 - val_accuracy: 0.3135 - val_loss: 1.9675\n",
      "Epoch 17/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3472 - loss: 1.8812 - val_accuracy: 0.3155 - val_loss: 1.9669\n",
      "Epoch 18/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3531 - loss: 1.8698 - val_accuracy: 0.3157 - val_loss: 1.9767\n",
      "Epoch 20/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3817 - loss: 1.7846 - val_accuracy: 0.3514 - val_loss: 1.8751\n",
      "Epoch 20/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3530 - loss: 1.8674 - val_accuracy: 0.3086 - val_loss: 1.9582\n",
      "Epoch 19/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3831 - loss: 1.7885 - val_accuracy: 0.3536 - val_loss: 1.8686\n",
      "Epoch 19/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3536 - loss: 1.8623 - val_accuracy: 0.3118 - val_loss: 1.9651\n",
      "Epoch 20/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3519 - loss: 1.8753 - val_accuracy: 0.3198 - val_loss: 1.9730\n",
      "Epoch 20/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3517 - loss: 1.8711 - val_accuracy: 0.3209 - val_loss: 1.9777\n",
      "Epoch 18/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3480 - loss: 1.8762 - val_accuracy: 0.3161 - val_loss: 1.9654\n",
      "Epoch 19/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3534 - loss: 1.8693 - val_accuracy: 0.3142 - val_loss: 1.9817\n",
      "Epoch 21/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3861 - loss: 1.7803 - val_accuracy: 0.3476 - val_loss: 1.8823\n",
      "Epoch 21/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3524 - loss: 1.8676 - val_accuracy: 0.3137 - val_loss: 1.9663\n",
      "Epoch 20/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3841 - loss: 1.7832 - val_accuracy: 0.3510 - val_loss: 1.8721\n",
      "Epoch 20/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3495 - loss: 1.8772 - val_accuracy: 0.3164 - val_loss: 1.9756\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3585 - loss: 1.8573 - val_accuracy: 0.3154 - val_loss: 1.9611\n",
      "Epoch 21/30\n",
      "Epoch 21/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3513 - loss: 1.8725 - val_accuracy: 0.3152 - val_loss: 1.9653\n",
      "Epoch 19/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3467 - loss: 1.8774 - val_accuracy: 0.3153 - val_loss: 1.9677\n",
      "Epoch 20/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3540 - loss: 1.8672 - val_accuracy: 0.3150 - val_loss: 1.9749\n",
      "Epoch 22/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3859 - loss: 1.7789 - val_accuracy: 0.3561 - val_loss: 1.8713\n",
      "Epoch 22/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3536 - loss: 1.8664 - val_accuracy: 0.3127 - val_loss: 1.9677\n",
      "Epoch 21/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3867 - loss: 1.7807 - val_accuracy: 0.3507 - val_loss: 1.8770\n",
      "Epoch 21/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3504 - loss: 1.8733 - val_accuracy: 0.3169 - val_loss: 1.9811\n",
      "Epoch 22/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3562 - loss: 1.8585 - val_accuracy: 0.3142 - val_loss: 1.9734\n",
      "Epoch 22/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3543 - loss: 1.8671 - val_accuracy: 0.3172 - val_loss: 1.9769\n",
      "Epoch 20/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3502 - loss: 1.8751 - val_accuracy: 0.3096 - val_loss: 1.9743\n",
      "Epoch 21/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3546 - loss: 1.8653 - val_accuracy: 0.3154 - val_loss: 1.9752\n",
      "Epoch 23/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3871 - loss: 1.7745 - val_accuracy: 0.3596 - val_loss: 1.8722\n",
      "Epoch 23/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3516 - loss: 1.8664 - val_accuracy: 0.3090 - val_loss: 1.9653\n",
      "Epoch 22/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3857 - loss: 1.7772 - val_accuracy: 0.3562 - val_loss: 1.8757\n",
      "Epoch 22/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3513 - loss: 1.8743 - val_accuracy: 0.3200 - val_loss: 1.9773\n",
      "Epoch 23/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3574 - loss: 1.8581 - val_accuracy: 0.3157 - val_loss: 1.9654\n",
      "Epoch 23/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3531 - loss: 1.8734 - val_accuracy: 0.3155 - val_loss: 1.9758\n",
      "Epoch 22/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3536 - loss: 1.8670 - val_accuracy: 0.3117 - val_loss: 1.9812\n",
      "Epoch 24/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3863 - loss: 1.7735 - val_accuracy: 0.3590 - val_loss: 1.8690\n",
      "Epoch 24/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3516 - loss: 1.8647 - val_accuracy: 0.3214 - val_loss: 1.9561\n",
      "Epoch 23/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3871 - loss: 1.7760 - val_accuracy: 0.3526 - val_loss: 1.8698\n",
      "Epoch 23/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3527 - loss: 1.8730 - val_accuracy: 0.3050 - val_loss: 1.9852\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3576 - loss: 1.8541 - val_accuracy: 0.3110 - val_loss: 1.9702\n",
      "Epoch 24/30\n",
      "Epoch 24/30\n",
      "391/391 - 5s - 12ms/step - accuracy: 0.3526 - loss: 1.8681 - val_accuracy: 0.3167 - val_loss: 1.9707\n",
      "Epoch 21/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3527 - loss: 1.8748 - val_accuracy: 0.3140 - val_loss: 1.9729\n",
      "Epoch 23/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3547 - loss: 1.8639 - val_accuracy: 0.3199 - val_loss: 1.9751\n",
      "Epoch 25/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3861 - loss: 1.7713 - val_accuracy: 0.3528 - val_loss: 1.8773\n",
      "Epoch 25/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3532 - loss: 1.8642 - val_accuracy: 0.3127 - val_loss: 1.9699\n",
      "Epoch 24/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3873 - loss: 1.7717 - val_accuracy: 0.3450 - val_loss: 1.8757\n",
      "Epoch 24/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3508 - loss: 1.8714 - val_accuracy: 0.3110 - val_loss: 1.9882\n",
      "Epoch 25/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3586 - loss: 1.8556 - val_accuracy: 0.3214 - val_loss: 1.9644\n",
      "Epoch 25/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3536 - loss: 1.8644 - val_accuracy: 0.3079 - val_loss: 1.9905\n",
      "Epoch 22/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3506 - loss: 1.8714 - val_accuracy: 0.3023 - val_loss: 1.9867\n",
      "Epoch 24/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3554 - loss: 1.8623 - val_accuracy: 0.3183 - val_loss: 1.9816\n",
      "Epoch 26/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3889 - loss: 1.7692 - val_accuracy: 0.3517 - val_loss: 1.8859\n",
      "Epoch 26/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3532 - loss: 1.8629 - val_accuracy: 0.3190 - val_loss: 1.9641\n",
      "Epoch 25/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3581 - loss: 1.8525 - val_accuracy: 0.3129 - val_loss: 1.9712\n",
      "Epoch 26/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3536 - loss: 1.8718 - val_accuracy: 0.3088 - val_loss: 1.9827\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3888 - loss: 1.7703 - val_accuracy: 0.3542 - val_loss: 1.8785\n",
      "Epoch 26/30\n",
      "Epoch 25/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3523 - loss: 1.8654 - val_accuracy: 0.3153 - val_loss: 1.9767\n",
      "Epoch 23/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3516 - loss: 1.8702 - val_accuracy: 0.3107 - val_loss: 1.9836\n",
      "Epoch 25/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3540 - loss: 1.8647 - val_accuracy: 0.3202 - val_loss: 1.9830\n",
      "Epoch 27/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3891 - loss: 1.7663 - val_accuracy: 0.3595 - val_loss: 1.8617\n",
      "Epoch 27/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3534 - loss: 1.8624 - val_accuracy: 0.3029 - val_loss: 1.9761\n",
      "Epoch 26/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3515 - loss: 1.8708 - val_accuracy: 0.3101 - val_loss: 1.9707\n",
      "Epoch 27/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3898 - loss: 1.7679 - val_accuracy: 0.3552 - val_loss: 1.8653\n",
      "Epoch 26/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3559 - loss: 1.8549 - val_accuracy: 0.3169 - val_loss: 1.9688\n",
      "Epoch 27/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3523 - loss: 1.8649 - val_accuracy: 0.3089 - val_loss: 1.9851\n",
      "Epoch 24/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3509 - loss: 1.8706 - val_accuracy: 0.3167 - val_loss: 1.9759\n",
      "Epoch 26/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3572 - loss: 1.8614 - val_accuracy: 0.3122 - val_loss: 1.9751\n",
      "Epoch 28/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3919 - loss: 1.7633 - val_accuracy: 0.3496 - val_loss: 1.8800\n",
      "Epoch 28/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3566 - loss: 1.8620 - val_accuracy: 0.3121 - val_loss: 1.9619\n",
      "Epoch 27/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3518 - loss: 1.8686 - val_accuracy: 0.3134 - val_loss: 1.9775\n",
      "Epoch 28/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3919 - loss: 1.7667 - val_accuracy: 0.3533 - val_loss: 1.8626\n",
      "Epoch 27/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3569 - loss: 1.8526 - val_accuracy: 0.3101 - val_loss: 1.9735\n",
      "Epoch 28/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3526 - loss: 1.8634 - val_accuracy: 0.3117 - val_loss: 1.9937\n",
      "Epoch 25/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3526 - loss: 1.8693 - val_accuracy: 0.3075 - val_loss: 1.9946\n",
      "Epoch 27/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3560 - loss: 1.8610 - val_accuracy: 0.3070 - val_loss: 1.9941\n",
      "Epoch 29/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3924 - loss: 1.7629 - val_accuracy: 0.3594 - val_loss: 1.8658\n",
      "Epoch 29/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3546 - loss: 1.8607 - val_accuracy: 0.3144 - val_loss: 1.9703\n",
      "Epoch 28/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3524 - loss: 1.8682 - val_accuracy: 0.3141 - val_loss: 1.9753\n",
      "Epoch 29/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3916 - loss: 1.7637 - val_accuracy: 0.3568 - val_loss: 1.8688\n",
      "Epoch 28/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3587 - loss: 1.8531 - val_accuracy: 0.3100 - val_loss: 1.9718\n",
      "Epoch 29/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3532 - loss: 1.8675 - val_accuracy: 0.3140 - val_loss: 1.9731\n",
      "Epoch 28/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3536 - loss: 1.8629 - val_accuracy: 0.3181 - val_loss: 1.9822\n",
      "Epoch 30/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3907 - loss: 1.7608 - val_accuracy: 0.3569 - val_loss: 1.8772\n",
      "Epoch 30/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3526 - loss: 1.8691 - val_accuracy: 0.3106 - val_loss: 1.9785\n",
      "Epoch 30/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3557 - loss: 1.8599 - val_accuracy: 0.3074 - val_loss: 1.9805\n",
      "Epoch 29/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3938 - loss: 1.7609 - val_accuracy: 0.3531 - val_loss: 1.8686\n",
      "Epoch 29/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3574 - loss: 1.8519 - val_accuracy: 0.3166 - val_loss: 1.9704\n",
      "Epoch 30/30\n",
      "391/391 - 5s - 13ms/step - accuracy: 0.3548 - loss: 1.8620 - val_accuracy: 0.3157 - val_loss: 1.9824\n",
      "Epoch 26/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3508 - loss: 1.8691 - val_accuracy: 0.3091 - val_loss: 1.9917\n",
      "Epoch 29/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3579 - loss: 1.8602 - val_accuracy: 0.3078 - val_loss: 1.9862\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3945 - loss: 1.7580 - val_accuracy: 0.3524 - val_loss: 1.8883\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3528 - loss: 1.8617 - val_accuracy: 0.3136 - val_loss: 1.9675\n",
      "Epoch 30/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3939 - loss: 1.7603 - val_accuracy: 0.3524 - val_loss: 1.8776\n",
      "Epoch 30/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3532 - loss: 1.8685 - val_accuracy: 0.3163 - val_loss: 1.9813\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3609 - loss: 1.8491 - val_accuracy: 0.3135 - val_loss: 1.9757\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3559 - loss: 1.8616 - val_accuracy: 0.3151 - val_loss: 1.9809\n",
      "Epoch 27/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3510 - loss: 1.8680 - val_accuracy: 0.3069 - val_loss: 1.9893\n",
      "Epoch 30/30\n",
      "391/391 - 2s - 5ms/step - accuracy: 0.3542 - loss: 1.8606 - val_accuracy: 0.3044 - val_loss: 1.9860\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3930 - loss: 1.7580 - val_accuracy: 0.3555 - val_loss: 1.8722\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3545 - loss: 1.8608 - val_accuracy: 0.3091 - val_loss: 1.9835\n",
      "Epoch 28/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3547 - loss: 1.8662 - val_accuracy: 0.3052 - val_loss: 1.9991\n",
      "391/391 - 1s - 4ms/step - accuracy: 0.3561 - loss: 1.8605 - val_accuracy: 0.3107 - val_loss: 1.9843\n",
      "Epoch 29/30\n",
      "391/391 - 1s - 4ms/step - accuracy: 0.3550 - loss: 1.8609 - val_accuracy: 0.3119 - val_loss: 1.9830\n",
      "Epoch 30/30\n",
      "391/391 - 1s - 3ms/step - accuracy: 0.3558 - loss: 1.8598 - val_accuracy: 0.3129 - val_loss: 1.9901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 16:40:36.007976: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:40:36.008074: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:40:36.014632: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:40:36.014716: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:40:36.015959: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:40:36.015959: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:40:36.016036: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:40:36.016038: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:40:36.029556: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-11-25 16:40:36.029621: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-11-25 16:40:36.029837: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-11-25 16:40:36.029905: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-11-25 16:40:36.046352: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:40:36.046516: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:40:36.046751: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:40:36.046938: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:40:36.052815: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:40:36.052815: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:40:36.052981: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:40:36.052981: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:40:36.055735: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:40:36.055930: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:40:36.056446: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:40:36.056522: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:40:36.058868: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:40:36.058945: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:40:36.059103: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:40:36.059166: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:40:36.068077: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-11-25 16:40:36.070596: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-11-25 16:40:36.070636: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-11-25 16:40:36.070798: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-11-25 16:40:36.086887: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:40:36.087343: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:40:36.092037: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:40:36.092201: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:40:36.092555: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:40:36.092763: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:40:36.094491: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:40:36.094692: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:40:36.515890: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-11-25 16:40:36.527734: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-11-25 16:40:36.528374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6573 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-11-25 16:40:36.539500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6579 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-11-25 16:40:36.557780: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-11-25 16:40:36.558354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6453 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-11-25 16:40:36.562001: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-11-25 16:40:36.563041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6125 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-11-25 16:40:36.575498: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-11-25 16:40:36.577570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6119 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-11-25 16:40:36.608405: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-11-25 16:40:36.609133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6085 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-11-25 16:40:36.639304: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-11-25 16:40:36.639956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6121 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-11-25 16:40:36.650909: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-11-25 16:40:36.651567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5993 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "Epoch 1/30\n",
      "Epoch 1/30\n",
      "Epoch 1/30\n",
      "Epoch 1/30\n",
      "Epoch 1/30\n",
      "Epoch 1/30\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 16:40:37.764129: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:40:37.764187: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:40:37.768528: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:40:37.768575: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:40:37.804550: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:40:37.804594: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:40:37.820976: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:40:37.821022: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:40:37.904672: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:40:37.904720: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:40:37.911517: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:40:37.911567: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:40:37.932721: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:40:37.932780: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:40:37.932834: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:40:37.932870: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732552838.221871  702849 service.cc:145] XLA service 0x77bc600192c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732552838.221918  702849 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-11-25 16:40:38.240864: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732552838.289198  702834 service.cc:145] XLA service 0x77bc5c030e90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732552838.289241  702834 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732552838.305258  702802 service.cc:145] XLA service 0x77bc4c033650 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732552838.305307  702802 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-11-25 16:40:38.305389: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-25 16:40:38.317182: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-11-25 16:40:38.326800: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732552838.330694  702815 service.cc:145] XLA service 0x77bc54032e90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732552838.330748  702815 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-11-25 16:40:38.350038: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-25 16:40:38.364707: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-11-25 16:40:38.414822: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-11-25 16:40:38.431719: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732552838.454138  702857 service.cc:145] XLA service 0x77bc60019ad0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732552838.454184  702857 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732552838.458492  702891 service.cc:145] XLA service 0x77bc540325b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732552838.458535  702891 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-11-25 16:40:38.472370: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-25 16:40:38.476358: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732552838.478684  702787 service.cc:145] XLA service 0x77bc58019c20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732552838.478726  702787 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732552838.484058  702876 service.cc:145] XLA service 0x77bc5c02f7d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732552838.484106  702876 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-11-25 16:40:38.496730: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-25 16:40:38.502387: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-25 16:40:38.530960: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-11-25 16:40:38.554750: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-11-25 16:40:38.570625: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-11-25 16:40:38.571913: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "I0000 00:00:1732552838.654637  702849 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1732552838.689687  702834 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-11-25 16:40:38.748889: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-11-25 16:40:38.751126: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:40:38.760524: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:540]  GpuTracer has collected 2002 callback api events and 1649 activity events. \n",
      "2024-11-25 16:40:38.773299: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:40:38.773769: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-11-25 16:40:38.774483: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: cifar_train/run1/2031/plugins/profile/2024_11_25_16_40_38/3a9247a29c0e.xplane.pb\n",
      "2024-11-25 16:40:38.775853: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:40:38.785385: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:540]  GpuTracer has collected 2000 callback api events and 1648 activity events. \n",
      "2024-11-25 16:40:38.797886: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:40:38.799017: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: cifar_train/run1/2103/plugins/profile/2024_11_25_16_40_38/3a9247a29c0e.xplane.pb\n",
      "I0000 00:00:1732552838.824877  702802 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1732552838.843975  702815 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-11-25 16:40:38.915959: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-11-25 16:40:38.918271: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:40:38.928588: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:540]  GpuTracer has collected 1998 callback api events and 1647 activity events. \n",
      "2024-11-25 16:40:38.937597: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-11-25 16:40:38.939735: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:40:38.943196: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:40:38.944626: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: cifar_train/run1/1230/plugins/profile/2024_11_25_16_40_38/3a9247a29c0e.xplane.pb\n",
      "2024-11-25 16:40:38.949602: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:540]  GpuTracer has collected 1998 callback api events and 1647 activity events. \n",
      "2024-11-25 16:40:38.965256: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:40:38.966596: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: cifar_train/run1/1302/plugins/profile/2024_11_25_16_40_38/3a9247a29c0e.xplane.pb\n",
      "I0000 00:00:1732552839.039499  702891 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1732552839.094716  702857 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1732552839.100133  702876 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1732552839.101655  702787 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-11-25 16:40:39.125334: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-11-25 16:40:39.127601: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:40:39.138640: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:540]  GpuTracer has collected 1998 callback api events and 1647 activity events. \n",
      "2024-11-25 16:40:39.153902: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:40:39.155166: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: cifar_train/run1/1320/plugins/profile/2024_11_25_16_40_39/3a9247a29c0e.xplane.pb\n",
      "2024-11-25 16:40:39.181096: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-11-25 16:40:39.183258: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:40:39.186214: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-11-25 16:40:39.186572: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-11-25 16:40:39.188410: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:40:39.188589: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:40:39.193375: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:540]  GpuTracer has collected 1998 callback api events and 1647 activity events. \n",
      "2024-11-25 16:40:39.198793: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:540]  GpuTracer has collected 1998 callback api events and 1647 activity events. \n",
      "2024-11-25 16:40:39.198910: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:540]  GpuTracer has collected 1998 callback api events and 1647 activity events. \n",
      "2024-11-25 16:40:39.209222: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:40:39.210678: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: cifar_train/run1/2013/plugins/profile/2024_11_25_16_40_39/3a9247a29c0e.xplane.pb\n",
      "2024-11-25 16:40:39.213617: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:40:39.215119: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: cifar_train/run1/1203/plugins/profile/2024_11_25_16_40_39/3a9247a29c0e.xplane.pb\n",
      "2024-11-25 16:40:39.215309: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:40:39.216579: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: cifar_train/run1/2130/plugins/profile/2024_11_25_16_40_39/3a9247a29c0e.xplane.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 - 5s - 13ms/step - accuracy: 0.2828 - loss: 2.0328 - val_accuracy: 0.3130 - val_loss: 1.9790\n",
      "Epoch 2/30\n",
      "391/391 - 5s - 13ms/step - accuracy: 0.2784 - loss: 2.0424 - val_accuracy: 0.3066 - val_loss: 1.9916\n",
      "Epoch 2/30\n",
      "391/391 - 5s - 13ms/step - accuracy: 0.2830 - loss: 2.0393 - val_accuracy: 0.3081 - val_loss: 1.9762\n",
      "Epoch 2/30\n",
      "391/391 - 5s - 13ms/step - accuracy: 0.2839 - loss: 2.0354 - val_accuracy: 0.3115 - val_loss: 1.9795\n",
      "Epoch 2/30\n",
      "391/391 - 5s - 13ms/step - accuracy: 0.2811 - loss: 2.0378 - val_accuracy: 0.3051 - val_loss: 1.9823\n",
      "Epoch 2/30\n",
      "391/391 - 5s - 14ms/step - accuracy: 0.2826 - loss: 2.0388 - val_accuracy: 0.3117 - val_loss: 1.9742\n",
      "Epoch 2/30\n",
      "391/391 - 5s - 14ms/step - accuracy: 0.2815 - loss: 2.0382 - val_accuracy: 0.3064 - val_loss: 1.9861\n",
      "Epoch 2/30\n",
      "391/391 - 6s - 15ms/step - accuracy: 0.2812 - loss: 2.0416 - val_accuracy: 0.3046 - val_loss: 1.9795\n",
      "Epoch 2/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3209 - loss: 1.9481 - val_accuracy: 0.3201 - val_loss: 1.9559\n",
      "Epoch 3/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3141 - loss: 1.9648 - val_accuracy: 0.3193 - val_loss: 1.9739\n",
      "Epoch 3/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3187 - loss: 1.9500 - val_accuracy: 0.3194 - val_loss: 1.9570\n",
      "Epoch 3/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3156 - loss: 1.9619 - val_accuracy: 0.3196 - val_loss: 1.9579\n",
      "Epoch 3/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3172 - loss: 1.9624 - val_accuracy: 0.3292 - val_loss: 1.9554\n",
      "Epoch 3/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3202 - loss: 1.9516 - val_accuracy: 0.3196 - val_loss: 1.9499\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3154 - loss: 1.9613 - val_accuracy: 0.3151 - val_loss: 1.9697\n",
      "Epoch 3/30\n",
      "Epoch 3/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3187 - loss: 1.9508 - val_accuracy: 0.3240 - val_loss: 1.9552\n",
      "Epoch 3/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3326 - loss: 1.9176 - val_accuracy: 0.3339 - val_loss: 1.9325\n",
      "Epoch 4/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3257 - loss: 1.9401 - val_accuracy: 0.3211 - val_loss: 1.9502\n",
      "Epoch 4/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3298 - loss: 1.9179 - val_accuracy: 0.3254 - val_loss: 1.9414\n",
      "Epoch 4/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3262 - loss: 1.9372 - val_accuracy: 0.3233 - val_loss: 1.9518\n",
      "Epoch 4/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3246 - loss: 1.9374 - val_accuracy: 0.3139 - val_loss: 1.9598\n",
      "Epoch 4/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3278 - loss: 1.9373 - val_accuracy: 0.3225 - val_loss: 1.9593\n",
      "Epoch 4/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3302 - loss: 1.9202 - val_accuracy: 0.3282 - val_loss: 1.9408\n",
      "Epoch 4/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3325 - loss: 1.9193 - val_accuracy: 0.3276 - val_loss: 1.9488\n",
      "Epoch 4/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3417 - loss: 1.8939 - val_accuracy: 0.3400 - val_loss: 1.9239\n",
      "Epoch 5/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3293 - loss: 1.9245 - val_accuracy: 0.3220 - val_loss: 1.9561\n",
      "Epoch 5/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3416 - loss: 1.8942 - val_accuracy: 0.3349 - val_loss: 1.9204\n",
      "Epoch 5/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3336 - loss: 1.9237 - val_accuracy: 0.3209 - val_loss: 1.9530\n",
      "Epoch 5/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3321 - loss: 1.9210 - val_accuracy: 0.3247 - val_loss: 1.9527\n",
      "Epoch 5/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3330 - loss: 1.9189 - val_accuracy: 0.3212 - val_loss: 1.9544\n",
      "Epoch 5/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3430 - loss: 1.8988 - val_accuracy: 0.3328 - val_loss: 1.9336\n",
      "Epoch 5/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3442 - loss: 1.8974 - val_accuracy: 0.3322 - val_loss: 1.9293\n",
      "Epoch 5/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3507 - loss: 1.8769 - val_accuracy: 0.3329 - val_loss: 1.9271\n",
      "Epoch 6/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3365 - loss: 1.9150 - val_accuracy: 0.3209 - val_loss: 1.9537\n",
      "Epoch 6/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3499 - loss: 1.8770 - val_accuracy: 0.3382 - val_loss: 1.9134\n",
      "Epoch 6/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3373 - loss: 1.9126 - val_accuracy: 0.3173 - val_loss: 1.9515\n",
      "Epoch 6/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3391 - loss: 1.9071 - val_accuracy: 0.3217 - val_loss: 1.9534\n",
      "Epoch 6/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3499 - loss: 1.8796 - val_accuracy: 0.3387 - val_loss: 1.9182\n",
      "Epoch 6/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3555 - loss: 1.8636 - val_accuracy: 0.3402 - val_loss: 1.9074\n",
      "Epoch 7/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3380 - loss: 1.9047 - val_accuracy: 0.3222 - val_loss: 1.9473\n",
      "Epoch 7/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3548 - loss: 1.8619 - val_accuracy: 0.3333 - val_loss: 1.9088\n",
      "Epoch 7/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3401 - loss: 1.9037 - val_accuracy: 0.3223 - val_loss: 1.9493\n",
      "Epoch 7/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3422 - loss: 1.9012 - val_accuracy: 0.3255 - val_loss: 1.9455\n",
      "Epoch 7/30\n",
      "391/391 - 5s - 13ms/step - accuracy: 0.3376 - loss: 1.9075 - val_accuracy: 0.3219 - val_loss: 1.9470\n",
      "Epoch 6/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3522 - loss: 1.8652 - val_accuracy: 0.3417 - val_loss: 1.9158\n",
      "Epoch 7/30\n",
      "391/391 - 5s - 13ms/step - accuracy: 0.3493 - loss: 1.8800 - val_accuracy: 0.3375 - val_loss: 1.9162\n",
      "Epoch 6/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3580 - loss: 1.8536 - val_accuracy: 0.3445 - val_loss: 1.9037\n",
      "Epoch 8/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3419 - loss: 1.8987 - val_accuracy: 0.3150 - val_loss: 1.9631\n",
      "Epoch 8/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3592 - loss: 1.8520 - val_accuracy: 0.3417 - val_loss: 1.9055\n",
      "Epoch 8/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3425 - loss: 1.8985 - val_accuracy: 0.3249 - val_loss: 1.9435\n",
      "Epoch 8/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3445 - loss: 1.8929 - val_accuracy: 0.3227 - val_loss: 1.9497\n",
      "Epoch 8/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3419 - loss: 1.8989 - val_accuracy: 0.3238 - val_loss: 1.9557\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3605 - loss: 1.8559 - val_accuracy: 0.3425 - val_loss: 1.9016\n",
      "Epoch 7/30\n",
      "Epoch 8/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3556 - loss: 1.8658 - val_accuracy: 0.3341 - val_loss: 1.9104\n",
      "Epoch 7/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3622 - loss: 1.8413 - val_accuracy: 0.3462 - val_loss: 1.9013\n",
      "Epoch 9/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3411 - loss: 1.8950 - val_accuracy: 0.3242 - val_loss: 1.9495\n",
      "Epoch 9/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3622 - loss: 1.8427 - val_accuracy: 0.3511 - val_loss: 1.8932\n",
      "Epoch 9/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3433 - loss: 1.8929 - val_accuracy: 0.3190 - val_loss: 1.9423\n",
      "Epoch 9/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3474 - loss: 1.8863 - val_accuracy: 0.3188 - val_loss: 1.9556\n",
      "Epoch 9/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3628 - loss: 1.8429 - val_accuracy: 0.3371 - val_loss: 1.9045\n",
      "Epoch 9/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3449 - loss: 1.8925 - val_accuracy: 0.3237 - val_loss: 1.9550\n",
      "Epoch 8/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3581 - loss: 1.8540 - val_accuracy: 0.3411 - val_loss: 1.9045\n",
      "Epoch 8/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3671 - loss: 1.8336 - val_accuracy: 0.3413 - val_loss: 1.8926\n",
      "Epoch 10/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3477 - loss: 1.8870 - val_accuracy: 0.3237 - val_loss: 1.9604\n",
      "Epoch 10/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3653 - loss: 1.8333 - val_accuracy: 0.3516 - val_loss: 1.8888\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3429 - loss: 1.8898 - val_accuracy: 0.3194 - val_loss: 1.9531\n",
      "Epoch 10/30\n",
      "Epoch 10/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3488 - loss: 1.8810 - val_accuracy: 0.3245 - val_loss: 1.9432\n",
      "Epoch 10/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3648 - loss: 1.8353 - val_accuracy: 0.3461 - val_loss: 1.8998\n",
      "Epoch 10/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3472 - loss: 1.8870 - val_accuracy: 0.3189 - val_loss: 1.9465\n",
      "Epoch 9/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3638 - loss: 1.8425 - val_accuracy: 0.3425 - val_loss: 1.9029\n",
      "Epoch 9/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3684 - loss: 1.8263 - val_accuracy: 0.3502 - val_loss: 1.8911\n",
      "Epoch 11/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3463 - loss: 1.8862 - val_accuracy: 0.3179 - val_loss: 1.9542\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3471 - loss: 1.8853 - val_accuracy: 0.3187 - val_loss: 1.9509\n",
      "Epoch 11/30\n",
      "Epoch 11/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3672 - loss: 1.8262 - val_accuracy: 0.3407 - val_loss: 1.9031\n",
      "Epoch 11/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3523 - loss: 1.8781 - val_accuracy: 0.3240 - val_loss: 1.9521\n",
      "Epoch 11/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3670 - loss: 1.8282 - val_accuracy: 0.3462 - val_loss: 1.8969\n",
      "Epoch 11/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3500 - loss: 1.8806 - val_accuracy: 0.3169 - val_loss: 1.9538\n",
      "Epoch 10/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3643 - loss: 1.8357 - val_accuracy: 0.3468 - val_loss: 1.8982\n",
      "Epoch 10/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3716 - loss: 1.8182 - val_accuracy: 0.3436 - val_loss: 1.8955\n",
      "Epoch 12/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3465 - loss: 1.8825 - val_accuracy: 0.3244 - val_loss: 1.9470\n",
      "Epoch 12/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3691 - loss: 1.8190 - val_accuracy: 0.3496 - val_loss: 1.8842\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3481 - loss: 1.8828 - val_accuracy: 0.3184 - val_loss: 1.9600\n",
      "Epoch 12/30\n",
      "Epoch 12/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3510 - loss: 1.8735 - val_accuracy: 0.3302 - val_loss: 1.9517\n",
      "Epoch 12/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3708 - loss: 1.8229 - val_accuracy: 0.3446 - val_loss: 1.9047\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3493 - loss: 1.8773 - val_accuracy: 0.3258 - val_loss: 1.9489\n",
      "Epoch 12/30\n",
      "Epoch 11/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3681 - loss: 1.8276 - val_accuracy: 0.3462 - val_loss: 1.9045\n",
      "Epoch 11/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3745 - loss: 1.8128 - val_accuracy: 0.3482 - val_loss: 1.8807\n",
      "Epoch 13/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3503 - loss: 1.8789 - val_accuracy: 0.3172 - val_loss: 1.9586\n",
      "Epoch 13/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3479 - loss: 1.8796 - val_accuracy: 0.3247 - val_loss: 1.9494\n",
      "Epoch 13/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3743 - loss: 1.8122 - val_accuracy: 0.3526 - val_loss: 1.8830\n",
      "Epoch 13/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3541 - loss: 1.8722 - val_accuracy: 0.3205 - val_loss: 1.9582\n",
      "Epoch 13/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3726 - loss: 1.8137 - val_accuracy: 0.3422 - val_loss: 1.8967\n",
      "Epoch 13/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3506 - loss: 1.8726 - val_accuracy: 0.3253 - val_loss: 1.9506\n",
      "Epoch 12/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3704 - loss: 1.8223 - val_accuracy: 0.3454 - val_loss: 1.8930\n",
      "Epoch 12/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3753 - loss: 1.8068 - val_accuracy: 0.3506 - val_loss: 1.8771\n",
      "Epoch 14/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3485 - loss: 1.8801 - val_accuracy: 0.3225 - val_loss: 1.9561\n",
      "Epoch 14/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3482 - loss: 1.8781 - val_accuracy: 0.3203 - val_loss: 1.9575\n",
      "Epoch 14/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3752 - loss: 1.8073 - val_accuracy: 0.3508 - val_loss: 1.8886\n",
      "Epoch 14/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3527 - loss: 1.8706 - val_accuracy: 0.3263 - val_loss: 1.9515\n",
      "Epoch 14/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3743 - loss: 1.8110 - val_accuracy: 0.3480 - val_loss: 1.8906\n",
      "Epoch 14/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3524 - loss: 1.8723 - val_accuracy: 0.3244 - val_loss: 1.9473\n",
      "Epoch 13/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3707 - loss: 1.8154 - val_accuracy: 0.3527 - val_loss: 1.8885\n",
      "Epoch 13/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3777 - loss: 1.8027 - val_accuracy: 0.3534 - val_loss: 1.8818\n",
      "Epoch 15/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3476 - loss: 1.8738 - val_accuracy: 0.3148 - val_loss: 1.9600\n",
      "Epoch 15/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3497 - loss: 1.8756 - val_accuracy: 0.3196 - val_loss: 1.9533\n",
      "Epoch 15/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3765 - loss: 1.8014 - val_accuracy: 0.3475 - val_loss: 1.8895\n",
      "Epoch 15/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3554 - loss: 1.8651 - val_accuracy: 0.3219 - val_loss: 1.9545\n",
      "Epoch 15/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3769 - loss: 1.8049 - val_accuracy: 0.3563 - val_loss: 1.8776\n",
      "Epoch 15/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3535 - loss: 1.8691 - val_accuracy: 0.3167 - val_loss: 1.9599\n",
      "Epoch 14/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3743 - loss: 1.8091 - val_accuracy: 0.3486 - val_loss: 1.8801\n",
      "Epoch 14/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3789 - loss: 1.7980 - val_accuracy: 0.3512 - val_loss: 1.8786\n",
      "Epoch 16/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3507 - loss: 1.8732 - val_accuracy: 0.3116 - val_loss: 1.9660\n",
      "Epoch 16/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3497 - loss: 1.8741 - val_accuracy: 0.3178 - val_loss: 1.9655\n",
      "Epoch 16/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3782 - loss: 1.7963 - val_accuracy: 0.3493 - val_loss: 1.8823\n",
      "Epoch 16/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3534 - loss: 1.8645 - val_accuracy: 0.3198 - val_loss: 1.9611\n",
      "Epoch 16/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3796 - loss: 1.7994 - val_accuracy: 0.3488 - val_loss: 1.8802\n",
      "Epoch 16/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3536 - loss: 1.8661 - val_accuracy: 0.3206 - val_loss: 1.9582\n",
      "Epoch 15/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3749 - loss: 1.8038 - val_accuracy: 0.3407 - val_loss: 1.9087\n",
      "Epoch 15/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3811 - loss: 1.7956 - val_accuracy: 0.3558 - val_loss: 1.8724\n",
      "Epoch 17/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3510 - loss: 1.8742 - val_accuracy: 0.3188 - val_loss: 1.9539\n",
      "Epoch 17/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3506 - loss: 1.8730 - val_accuracy: 0.3203 - val_loss: 1.9591\n",
      "Epoch 17/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3798 - loss: 1.7919 - val_accuracy: 0.3547 - val_loss: 1.8735\n",
      "Epoch 17/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3557 - loss: 1.8635 - val_accuracy: 0.3184 - val_loss: 1.9606\n",
      "Epoch 17/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3814 - loss: 1.7946 - val_accuracy: 0.3439 - val_loss: 1.8822\n",
      "Epoch 17/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3565 - loss: 1.8640 - val_accuracy: 0.3098 - val_loss: 1.9621\n",
      "Epoch 16/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3776 - loss: 1.7980 - val_accuracy: 0.3509 - val_loss: 1.8799\n",
      "Epoch 16/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3803 - loss: 1.7894 - val_accuracy: 0.3516 - val_loss: 1.8792\n",
      "Epoch 18/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3537 - loss: 1.8686 - val_accuracy: 0.3168 - val_loss: 1.9571\n",
      "Epoch 18/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3527 - loss: 1.8719 - val_accuracy: 0.3205 - val_loss: 1.9510\n",
      "Epoch 18/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3803 - loss: 1.7895 - val_accuracy: 0.3499 - val_loss: 1.8850\n",
      "Epoch 18/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3558 - loss: 1.8603 - val_accuracy: 0.3206 - val_loss: 1.9637\n",
      "Epoch 18/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3789 - loss: 1.7939 - val_accuracy: 0.3514 - val_loss: 1.8781\n",
      "Epoch 18/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3546 - loss: 1.8622 - val_accuracy: 0.3199 - val_loss: 1.9553\n",
      "Epoch 17/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3780 - loss: 1.7958 - val_accuracy: 0.3543 - val_loss: 1.8748\n",
      "Epoch 17/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3836 - loss: 1.7862 - val_accuracy: 0.3492 - val_loss: 1.8791\n",
      "Epoch 19/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3522 - loss: 1.8688 - val_accuracy: 0.3213 - val_loss: 1.9564\n",
      "Epoch 19/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3500 - loss: 1.8701 - val_accuracy: 0.3147 - val_loss: 1.9584\n",
      "Epoch 19/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3824 - loss: 1.7871 - val_accuracy: 0.3574 - val_loss: 1.8707\n",
      "Epoch 19/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3564 - loss: 1.8617 - val_accuracy: 0.3170 - val_loss: 1.9536\n",
      "Epoch 19/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3841 - loss: 1.7878 - val_accuracy: 0.3577 - val_loss: 1.8705\n",
      "Epoch 19/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3559 - loss: 1.8595 - val_accuracy: 0.3149 - val_loss: 1.9660\n",
      "Epoch 18/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3810 - loss: 1.7912 - val_accuracy: 0.3428 - val_loss: 1.8912\n",
      "Epoch 18/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3836 - loss: 1.7831 - val_accuracy: 0.3550 - val_loss: 1.8669\n",
      "Epoch 20/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3512 - loss: 1.8697 - val_accuracy: 0.3185 - val_loss: 1.9664\n",
      "Epoch 20/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3533 - loss: 1.8687 - val_accuracy: 0.3100 - val_loss: 1.9733\n",
      "Epoch 20/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3840 - loss: 1.7829 - val_accuracy: 0.3517 - val_loss: 1.8731\n",
      "Epoch 20/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3566 - loss: 1.8593 - val_accuracy: 0.3200 - val_loss: 1.9580\n",
      "Epoch 20/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3548 - loss: 1.8597 - val_accuracy: 0.3241 - val_loss: 1.9552\n",
      "Epoch 19/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3830 - loss: 1.7838 - val_accuracy: 0.3501 - val_loss: 1.8718\n",
      "Epoch 20/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3812 - loss: 1.7886 - val_accuracy: 0.3547 - val_loss: 1.8741\n",
      "Epoch 19/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3849 - loss: 1.7800 - val_accuracy: 0.3538 - val_loss: 1.8710\n",
      "Epoch 21/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3524 - loss: 1.8687 - val_accuracy: 0.3181 - val_loss: 1.9570\n",
      "Epoch 21/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3521 - loss: 1.8702 - val_accuracy: 0.3136 - val_loss: 1.9756\n",
      "Epoch 21/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3834 - loss: 1.7811 - val_accuracy: 0.3593 - val_loss: 1.8727\n",
      "Epoch 21/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3552 - loss: 1.8578 - val_accuracy: 0.3287 - val_loss: 1.9566\n",
      "Epoch 21/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3576 - loss: 1.8591 - val_accuracy: 0.3183 - val_loss: 1.9701\n",
      "Epoch 20/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3827 - loss: 1.7813 - val_accuracy: 0.3569 - val_loss: 1.8778\n",
      "Epoch 21/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3829 - loss: 1.7839 - val_accuracy: 0.3408 - val_loss: 1.8837\n",
      "Epoch 20/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3866 - loss: 1.7764 - val_accuracy: 0.3515 - val_loss: 1.8775\n",
      "Epoch 22/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3505 - loss: 1.8668 - val_accuracy: 0.3154 - val_loss: 1.9640\n",
      "Epoch 22/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3857 - loss: 1.7772 - val_accuracy: 0.3539 - val_loss: 1.8766\n",
      "Epoch 22/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3544 - loss: 1.8669 - val_accuracy: 0.3199 - val_loss: 1.9615\n",
      "Epoch 22/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3598 - loss: 1.8551 - val_accuracy: 0.3092 - val_loss: 1.9755\n",
      "Epoch 22/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3546 - loss: 1.8592 - val_accuracy: 0.3167 - val_loss: 1.9600\n",
      "Epoch 21/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3856 - loss: 1.7813 - val_accuracy: 0.3564 - val_loss: 1.8764\n",
      "Epoch 22/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3848 - loss: 1.7815 - val_accuracy: 0.3530 - val_loss: 1.8754\n",
      "Epoch 21/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3873 - loss: 1.7748 - val_accuracy: 0.3585 - val_loss: 1.8708\n",
      "Epoch 23/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3523 - loss: 1.8684 - val_accuracy: 0.3096 - val_loss: 1.9685\n",
      "Epoch 23/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3512 - loss: 1.8677 - val_accuracy: 0.3180 - val_loss: 1.9575\n",
      "Epoch 23/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3868 - loss: 1.7728 - val_accuracy: 0.3566 - val_loss: 1.8734\n",
      "Epoch 23/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3561 - loss: 1.8566 - val_accuracy: 0.3132 - val_loss: 1.9719\n",
      "Epoch 23/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3562 - loss: 1.8580 - val_accuracy: 0.3195 - val_loss: 1.9622\n",
      "Epoch 22/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3835 - loss: 1.7767 - val_accuracy: 0.3556 - val_loss: 1.8654\n",
      "Epoch 23/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3847 - loss: 1.7795 - val_accuracy: 0.3527 - val_loss: 1.8689\n",
      "Epoch 22/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3889 - loss: 1.7712 - val_accuracy: 0.3553 - val_loss: 1.8666\n",
      "Epoch 24/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3542 - loss: 1.8644 - val_accuracy: 0.3135 - val_loss: 1.9618\n",
      "Epoch 24/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3549 - loss: 1.8641 - val_accuracy: 0.3126 - val_loss: 1.9743\n",
      "Epoch 24/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3880 - loss: 1.7709 - val_accuracy: 0.3514 - val_loss: 1.8760\n",
      "Epoch 24/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3570 - loss: 1.8543 - val_accuracy: 0.3105 - val_loss: 1.9682\n",
      "Epoch 24/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3557 - loss: 1.8551 - val_accuracy: 0.3133 - val_loss: 1.9675\n",
      "Epoch 23/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3879 - loss: 1.7744 - val_accuracy: 0.3564 - val_loss: 1.8736\n",
      "Epoch 24/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3859 - loss: 1.7767 - val_accuracy: 0.3512 - val_loss: 1.8762\n",
      "Epoch 23/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3889 - loss: 1.7704 - val_accuracy: 0.3433 - val_loss: 1.8812\n",
      "Epoch 25/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3545 - loss: 1.8621 - val_accuracy: 0.3074 - val_loss: 1.9661\n",
      "Epoch 25/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3552 - loss: 1.8629 - val_accuracy: 0.3180 - val_loss: 1.9673\n",
      "Epoch 25/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3573 - loss: 1.8538 - val_accuracy: 0.3176 - val_loss: 1.9738\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3896 - loss: 1.7689 - val_accuracy: 0.3518 - val_loss: 1.8778\n",
      "Epoch 25/30\n",
      "Epoch 25/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3580 - loss: 1.8543 - val_accuracy: 0.3118 - val_loss: 1.9694\n",
      "Epoch 24/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3878 - loss: 1.7714 - val_accuracy: 0.3478 - val_loss: 1.8721\n",
      "Epoch 25/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3875 - loss: 1.7735 - val_accuracy: 0.3494 - val_loss: 1.8782\n",
      "Epoch 24/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3919 - loss: 1.7679 - val_accuracy: 0.3552 - val_loss: 1.8677\n",
      "Epoch 26/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3551 - loss: 1.8614 - val_accuracy: 0.3137 - val_loss: 1.9662\n",
      "Epoch 26/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3595 - loss: 1.8516 - val_accuracy: 0.3174 - val_loss: 1.9662\n",
      "Epoch 26/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3545 - loss: 1.8635 - val_accuracy: 0.3229 - val_loss: 1.9671\n",
      "Epoch 26/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3896 - loss: 1.7685 - val_accuracy: 0.3494 - val_loss: 1.8808\n",
      "Epoch 26/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3570 - loss: 1.8542 - val_accuracy: 0.3099 - val_loss: 1.9696\n",
      "Epoch 25/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3899 - loss: 1.7684 - val_accuracy: 0.3491 - val_loss: 1.8739\n",
      "Epoch 26/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3874 - loss: 1.7713 - val_accuracy: 0.3537 - val_loss: 1.8757\n",
      "Epoch 25/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3913 - loss: 1.7637 - val_accuracy: 0.3522 - val_loss: 1.8678\n",
      "Epoch 27/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3518 - loss: 1.8630 - val_accuracy: 0.3143 - val_loss: 1.9548\n",
      "Epoch 27/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3591 - loss: 1.8523 - val_accuracy: 0.3054 - val_loss: 1.9752\n",
      "Epoch 27/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3549 - loss: 1.8604 - val_accuracy: 0.3180 - val_loss: 1.9737\n",
      "Epoch 27/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3908 - loss: 1.7659 - val_accuracy: 0.3588 - val_loss: 1.8678\n",
      "Epoch 27/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3565 - loss: 1.8533 - val_accuracy: 0.3120 - val_loss: 1.9706\n",
      "Epoch 26/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3895 - loss: 1.7664 - val_accuracy: 0.3514 - val_loss: 1.8766\n",
      "Epoch 27/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3902 - loss: 1.7680 - val_accuracy: 0.3498 - val_loss: 1.8785\n",
      "Epoch 26/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3926 - loss: 1.7619 - val_accuracy: 0.3460 - val_loss: 1.8762\n",
      "Epoch 28/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3568 - loss: 1.8606 - val_accuracy: 0.3196 - val_loss: 1.9685\n",
      "Epoch 28/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3544 - loss: 1.8634 - val_accuracy: 0.3156 - val_loss: 1.9746\n",
      "Epoch 28/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3934 - loss: 1.7614 - val_accuracy: 0.3566 - val_loss: 1.8658\n",
      "Epoch 28/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3592 - loss: 1.8513 - val_accuracy: 0.3136 - val_loss: 1.9789\n",
      "Epoch 28/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3596 - loss: 1.8525 - val_accuracy: 0.3178 - val_loss: 1.9724\n",
      "Epoch 27/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3914 - loss: 1.7642 - val_accuracy: 0.3512 - val_loss: 1.8823\n",
      "Epoch 28/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3903 - loss: 1.7665 - val_accuracy: 0.3618 - val_loss: 1.8709\n",
      "Epoch 27/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3544 - loss: 1.8582 - val_accuracy: 0.3090 - val_loss: 1.9752\n",
      "Epoch 29/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3922 - loss: 1.7606 - val_accuracy: 0.3600 - val_loss: 1.8612\n",
      "Epoch 29/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3565 - loss: 1.8628 - val_accuracy: 0.3042 - val_loss: 1.9832\n",
      "Epoch 29/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3918 - loss: 1.7621 - val_accuracy: 0.3562 - val_loss: 1.8733\n",
      "Epoch 29/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3592 - loss: 1.8514 - val_accuracy: 0.3142 - val_loss: 1.9798\n",
      "Epoch 29/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3585 - loss: 1.8533 - val_accuracy: 0.3162 - val_loss: 1.9693\n",
      "Epoch 28/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3908 - loss: 1.7644 - val_accuracy: 0.3548 - val_loss: 1.8734\n",
      "Epoch 29/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3906 - loss: 1.7636 - val_accuracy: 0.3562 - val_loss: 1.8682\n",
      "Epoch 28/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3560 - loss: 1.8602 - val_accuracy: 0.3023 - val_loss: 1.9780\n",
      "Epoch 30/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3947 - loss: 1.7602 - val_accuracy: 0.3524 - val_loss: 1.8812\n",
      "Epoch 30/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3548 - loss: 1.8609 - val_accuracy: 0.3163 - val_loss: 1.9636\n",
      "Epoch 30/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3935 - loss: 1.7589 - val_accuracy: 0.3500 - val_loss: 1.8735\n",
      "Epoch 30/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3590 - loss: 1.8501 - val_accuracy: 0.3077 - val_loss: 1.9874\n",
      "Epoch 30/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3580 - loss: 1.8523 - val_accuracy: 0.3191 - val_loss: 1.9692\n",
      "Epoch 29/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3918 - loss: 1.7633 - val_accuracy: 0.3494 - val_loss: 1.8773\n",
      "Epoch 30/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3914 - loss: 1.7630 - val_accuracy: 0.3588 - val_loss: 1.8739\n",
      "Epoch 29/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3537 - loss: 1.8616 - val_accuracy: 0.3142 - val_loss: 1.9650\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3562 - loss: 1.8605 - val_accuracy: 0.3117 - val_loss: 1.9731\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3937 - loss: 1.7571 - val_accuracy: 0.3588 - val_loss: 1.8634\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3942 - loss: 1.7574 - val_accuracy: 0.3539 - val_loss: 1.8827\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3598 - loss: 1.8509 - val_accuracy: 0.3166 - val_loss: 1.9734\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3583 - loss: 1.8497 - val_accuracy: 0.3118 - val_loss: 1.9835\n",
      "Epoch 30/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3935 - loss: 1.7591 - val_accuracy: 0.3501 - val_loss: 1.8686\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3918 - loss: 1.7612 - val_accuracy: 0.3532 - val_loss: 1.8766\n",
      "Epoch 30/30\n",
      "391/391 - 2s - 5ms/step - accuracy: 0.3602 - loss: 1.8495 - val_accuracy: 0.3064 - val_loss: 1.9751\n",
      "391/391 - 2s - 4ms/step - accuracy: 0.3946 - loss: 1.7606 - val_accuracy: 0.3578 - val_loss: 1.8717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 16:41:59.329148: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:41:59.329623: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:41:59.337153: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:41:59.337153: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:41:59.337228: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:41:59.337232: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:41:59.341224: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:41:59.341331: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:41:59.349537: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-11-25 16:41:59.349683: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-11-25 16:41:59.349817: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-11-25 16:41:59.352417: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-11-25 16:41:59.364257: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:41:59.364403: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:41:59.372979: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:41:59.372979: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:41:59.373139: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:41:59.373162: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:41:59.375420: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:41:59.375621: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:41:59.377456: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:41:59.377538: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:41:59.378611: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:41:59.378685: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:41:59.380075: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:41:59.380147: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:41:59.381154: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:41:59.381216: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:41:59.389090: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-11-25 16:41:59.390068: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-11-25 16:41:59.391548: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-11-25 16:41:59.391985: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-11-25 16:41:59.413587: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:41:59.413851: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:41:59.415875: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:41:59.415875: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:41:59.416076: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:41:59.416088: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:41:59.416381: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:41:59.416539: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:41:59.713290: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-11-25 16:41:59.721290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6719 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-11-25 16:41:59.770647: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-11-25 16:41:59.773123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6585 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-11-25 16:41:59.783459: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-11-25 16:41:59.784159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6367 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-11-25 16:41:59.791960: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-11-25 16:41:59.792398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6361 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-11-25 16:41:59.810437: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-11-25 16:41:59.811048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5993 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-11-25 16:41:59.811055: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-11-25 16:41:59.811500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5961 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-11-25 16:41:59.816214: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-11-25 16:41:59.816574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5961 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-11-25 16:41:59.866874: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-11-25 16:41:59.867494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5993 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "Epoch 1/30\n",
      "Epoch 1/30\n",
      "Epoch 1/30\n",
      "Epoch 1/30\n",
      "Epoch 1/30\n",
      "Epoch 1/30\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 16:42:00.827096: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:42:00.827149: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:42:00.857424: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:42:00.857471: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:42:00.929949: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:42:00.930108: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:42:00.938291: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:42:00.938418: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:42:00.953336: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:42:00.953470: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:42:00.966121: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:42:00.966247: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:42:00.991216: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:42:00.991340: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-25 16:42:01.031529: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-25 16:42:01.031587: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732552921.309900  713025 service.cc:145] XLA service 0x77bc54031a70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732552921.309949  713025 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-11-25 16:42:01.329835: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732552921.403252  712997 service.cc:145] XLA service 0x77bc68019230 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732552921.403298  712997 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732552921.415511  713037 service.cc:145] XLA service 0x77bc5c018b10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732552921.415563  713037 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-11-25 16:42:01.419092: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-25 16:42:01.419510: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-11-25 16:42:01.436956: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732552921.450568  712969 service.cc:145] XLA service 0x77bc540188d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732552921.450614  712969 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-11-25 16:42:01.470727: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732552921.473490  712934 service.cc:145] XLA service 0x77bc6c0167d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732552921.473530  712934 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732552921.488253  712980 service.cc:145] XLA service 0x77bc68018e40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732552921.488302  712980 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-11-25 16:42:01.489877: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-25 16:42:01.490749: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732552921.496998  712955 service.cc:145] XLA service 0x77bc580322f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732552921.497044  712955 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-11-25 16:42:01.505383: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-11-25 16:42:01.508243: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-25 16:42:01.515686: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732552921.545421  713010 service.cc:145] XLA service 0x77bc5c0187a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732552921.545467  713010 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-11-25 16:42:01.545602: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-11-25 16:42:01.551929: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-11-25 16:42:01.566849: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-25 16:42:01.573930: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-11-25 16:42:01.592487: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-11-25 16:42:01.629080: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "I0000 00:00:1732552921.781184  713025 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-11-25 16:42:01.853869: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-11-25 16:42:01.855594: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:42:01.862100: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:540]  GpuTracer has collected 2000 callback api events and 1648 activity events. \n",
      "2024-11-25 16:42:01.869222: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:42:01.869925: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: cifar_train/run1/3012/plugins/profile/2024_11_25_16_42_01/3a9247a29c0e.xplane.pb\n",
      "I0000 00:00:1732552921.995150  713037 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-11-25 16:42:02.086311: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-11-25 16:42:02.088419: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:42:02.098661: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:540]  GpuTracer has collected 2000 callback api events and 1648 activity events. \n",
      "2024-11-25 16:42:02.112462: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:42:02.113676: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: cifar_train/run1/3210/plugins/profile/2024_11_25_16_42_02/3a9247a29c0e.xplane.pb\n",
      "I0000 00:00:1732552922.130962  712997 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-11-25 16:42:02.219165: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-11-25 16:42:02.221273: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "I0000 00:00:1732552922.227016  712969 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-11-25 16:42:02.231518: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:540]  GpuTracer has collected 1998 callback api events and 1647 activity events. \n",
      "I0000 00:00:1732552922.245756  712955 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-11-25 16:42:02.246071: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:42:02.247405: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: cifar_train/run1/2301/plugins/profile/2024_11_25_16_42_02/3a9247a29c0e.xplane.pb\n",
      "I0000 00:00:1732552922.248396  712934 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1732552922.248405  712980 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1732552922.250593  713010 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-11-25 16:42:02.318475: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-11-25 16:42:02.320598: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:42:02.329649: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:540]  GpuTracer has collected 1998 callback api events and 1647 activity events. \n",
      "2024-11-25 16:42:02.335671: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-11-25 16:42:02.337145: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-11-25 16:42:02.337145: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-11-25 16:42:02.337790: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:42:02.339164: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:42:02.339164: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:42:02.339297: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-11-25 16:42:02.341604: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-11-25 16:42:02.343640: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:42:02.344914: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: cifar_train/run1/3201/plugins/profile/2024_11_25_16_42_02/3a9247a29c0e.xplane.pb\n",
      "2024-11-25 16:42:02.347589: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:540]  GpuTracer has collected 1998 callback api events and 1647 activity events. \n",
      "2024-11-25 16:42:02.349518: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:540]  GpuTracer has collected 1998 callback api events and 1647 activity events. \n",
      "2024-11-25 16:42:02.349518: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:540]  GpuTracer has collected 1998 callback api events and 1647 activity events. \n",
      "2024-11-25 16:42:02.352042: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:540]  GpuTracer has collected 1998 callback api events and 1647 activity events. \n",
      "2024-11-25 16:42:02.363363: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:42:02.363851: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:42:02.363851: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:42:02.364570: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: cifar_train/run1/2310/plugins/profile/2024_11_25_16_42_02/3a9247a29c0e.xplane.pb\n",
      "2024-11-25 16:42:02.365328: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: cifar_train/run1/3021/plugins/profile/2024_11_25_16_42_02/3a9247a29c0e.xplane.pb\n",
      "2024-11-25 16:42:02.365328: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: cifar_train/run1/3102/plugins/profile/2024_11_25_16_42_02/3a9247a29c0e.xplane.pb\n",
      "2024-11-25 16:42:02.366862: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-25 16:42:02.368354: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: cifar_train/run1/3120/plugins/profile/2024_11_25_16_42_02/3a9247a29c0e.xplane.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 - 5s - 13ms/step - accuracy: 0.2795 - loss: 2.0415 - val_accuracy: 0.3049 - val_loss: 1.9750\n",
      "Epoch 2/30\n",
      "391/391 - 5s - 13ms/step - accuracy: 0.2803 - loss: 2.0447 - val_accuracy: 0.2977 - val_loss: 1.9940\n",
      "Epoch 2/30\n",
      "391/391 - 5s - 14ms/step - accuracy: 0.2807 - loss: 2.0402 - val_accuracy: 0.3011 - val_loss: 1.9899\n",
      "Epoch 2/30\n",
      "391/391 - 5s - 14ms/step - accuracy: 0.2798 - loss: 2.0437 - val_accuracy: 0.3051 - val_loss: 1.9861\n",
      "Epoch 2/30\n",
      "391/391 - 6s - 14ms/step - accuracy: 0.2830 - loss: 2.0365 - val_accuracy: 0.3116 - val_loss: 1.9768\n",
      "Epoch 2/30\n",
      "391/391 - 6s - 14ms/step - accuracy: 0.2833 - loss: 2.0340 - val_accuracy: 0.3078 - val_loss: 1.9790\n",
      "391/391 - 6s - 14ms/step - accuracy: 0.2820 - loss: 2.0381 - val_accuracy: 0.3051 - val_loss: 1.9853\n",
      "391/391 - 6s - 14ms/step - accuracy: 0.2761 - loss: 2.0515 - val_accuracy: 0.3052 - val_loss: 1.9926\n",
      "Epoch 2/30\n",
      "Epoch 2/30\n",
      "Epoch 2/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3203 - loss: 1.9507 - val_accuracy: 0.3207 - val_loss: 1.9495\n",
      "Epoch 3/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3136 - loss: 1.9684 - val_accuracy: 0.3278 - val_loss: 1.9671\n",
      "Epoch 3/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3126 - loss: 1.9681 - val_accuracy: 0.3166 - val_loss: 1.9747\n",
      "Epoch 3/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3131 - loss: 1.9673 - val_accuracy: 0.3157 - val_loss: 1.9663\n",
      "Epoch 3/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3180 - loss: 1.9605 - val_accuracy: 0.3257 - val_loss: 1.9528\n",
      "Epoch 3/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3134 - loss: 1.9619 - val_accuracy: 0.3198 - val_loss: 1.9614\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3186 - loss: 1.9509 - val_accuracy: 0.3244 - val_loss: 1.9439\n",
      "Epoch 3/30\n",
      "Epoch 3/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3146 - loss: 1.9681 - val_accuracy: 0.3097 - val_loss: 1.9720\n",
      "Epoch 3/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3319 - loss: 1.9165 - val_accuracy: 0.3347 - val_loss: 1.9273\n",
      "Epoch 4/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3263 - loss: 1.9423 - val_accuracy: 0.3208 - val_loss: 1.9639\n",
      "Epoch 4/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3229 - loss: 1.9459 - val_accuracy: 0.3198 - val_loss: 1.9593\n",
      "Epoch 4/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3245 - loss: 1.9420 - val_accuracy: 0.3076 - val_loss: 1.9799\n",
      "Epoch 4/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3320 - loss: 1.9191 - val_accuracy: 0.3334 - val_loss: 1.9353\n",
      "Epoch 4/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3277 - loss: 1.9366 - val_accuracy: 0.3195 - val_loss: 1.9567\n",
      "Epoch 4/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3242 - loss: 1.9389 - val_accuracy: 0.3199 - val_loss: 1.9632\n",
      "Epoch 4/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3245 - loss: 1.9442 - val_accuracy: 0.3157 - val_loss: 1.9683\n",
      "Epoch 4/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3427 - loss: 1.8945 - val_accuracy: 0.3389 - val_loss: 1.9256\n",
      "Epoch 5/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3323 - loss: 1.9289 - val_accuracy: 0.3190 - val_loss: 1.9660\n",
      "Epoch 5/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3339 - loss: 1.9295 - val_accuracy: 0.3199 - val_loss: 1.9559\n",
      "Epoch 5/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3321 - loss: 1.9262 - val_accuracy: 0.3242 - val_loss: 1.9632\n",
      "Epoch 5/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3364 - loss: 1.9177 - val_accuracy: 0.3268 - val_loss: 1.9426\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3303 - loss: 1.9231 - val_accuracy: 0.3253 - val_loss: 1.9597\n",
      "Epoch 5/30\n",
      "Epoch 5/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3420 - loss: 1.8974 - val_accuracy: 0.3329 - val_loss: 1.9259\n",
      "Epoch 5/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3313 - loss: 1.9268 - val_accuracy: 0.3131 - val_loss: 1.9750\n",
      "Epoch 5/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3495 - loss: 1.8779 - val_accuracy: 0.3338 - val_loss: 1.9177\n",
      "Epoch 6/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3353 - loss: 1.9184 - val_accuracy: 0.3304 - val_loss: 1.9539\n",
      "Epoch 6/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3342 - loss: 1.9195 - val_accuracy: 0.3213 - val_loss: 1.9532\n",
      "Epoch 6/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3392 - loss: 1.9144 - val_accuracy: 0.3263 - val_loss: 1.9569\n",
      "Epoch 6/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3371 - loss: 1.9128 - val_accuracy: 0.3266 - val_loss: 1.9487\n",
      "Epoch 6/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3490 - loss: 1.8789 - val_accuracy: 0.3348 - val_loss: 1.9189\n",
      "Epoch 6/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3363 - loss: 1.9151 - val_accuracy: 0.3185 - val_loss: 1.9558\n",
      "Epoch 6/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3550 - loss: 1.8639 - val_accuracy: 0.3323 - val_loss: 1.9204\n",
      "Epoch 7/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3361 - loss: 1.9120 - val_accuracy: 0.3211 - val_loss: 1.9614\n",
      "Epoch 7/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3380 - loss: 1.9123 - val_accuracy: 0.3166 - val_loss: 1.9615\n",
      "Epoch 7/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3410 - loss: 1.9065 - val_accuracy: 0.3164 - val_loss: 1.9628\n",
      "Epoch 7/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3373 - loss: 1.9048 - val_accuracy: 0.3256 - val_loss: 1.9507\n",
      "Epoch 7/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3541 - loss: 1.8659 - val_accuracy: 0.3281 - val_loss: 1.9176\n",
      "Epoch 7/30\n",
      "391/391 - 5s - 13ms/step - accuracy: 0.3366 - loss: 1.9088 - val_accuracy: 0.3303 - val_loss: 1.9469\n",
      "Epoch 6/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3414 - loss: 1.9059 - val_accuracy: 0.3224 - val_loss: 1.9563\n",
      "Epoch 7/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3590 - loss: 1.8538 - val_accuracy: 0.3442 - val_loss: 1.9001\n",
      "Epoch 8/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3392 - loss: 1.9066 - val_accuracy: 0.3155 - val_loss: 1.9601\n",
      "Epoch 8/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3408 - loss: 1.9038 - val_accuracy: 0.3125 - val_loss: 1.9694\n",
      "Epoch 8/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3419 - loss: 1.9022 - val_accuracy: 0.3195 - val_loss: 1.9614\n",
      "Epoch 8/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3413 - loss: 1.8974 - val_accuracy: 0.3244 - val_loss: 1.9516\n",
      "Epoch 8/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3603 - loss: 1.8522 - val_accuracy: 0.3406 - val_loss: 1.9058\n",
      "Epoch 8/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3432 - loss: 1.9015 - val_accuracy: 0.3218 - val_loss: 1.9589\n",
      "Epoch 8/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3623 - loss: 1.8418 - val_accuracy: 0.3482 - val_loss: 1.8950\n",
      "Epoch 9/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3416 - loss: 1.8991 - val_accuracy: 0.3156 - val_loss: 1.9650\n",
      "Epoch 9/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3418 - loss: 1.8990 - val_accuracy: 0.3220 - val_loss: 1.9607\n",
      "Epoch 9/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3440 - loss: 1.8949 - val_accuracy: 0.3185 - val_loss: 1.9588\n",
      "Epoch 9/30\n",
      "391/391 - 5s - 13ms/step - accuracy: 0.3416 - loss: 1.8986 - val_accuracy: 0.3216 - val_loss: 1.9473\n",
      "Epoch 7/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3423 - loss: 1.8944 - val_accuracy: 0.3191 - val_loss: 1.9519\n",
      "Epoch 9/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3641 - loss: 1.8438 - val_accuracy: 0.3460 - val_loss: 1.8912\n",
      "Epoch 9/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3452 - loss: 1.8948 - val_accuracy: 0.3156 - val_loss: 1.9682\n",
      "Epoch 9/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3656 - loss: 1.8345 - val_accuracy: 0.3422 - val_loss: 1.8942\n",
      "Epoch 10/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3448 - loss: 1.8953 - val_accuracy: 0.3227 - val_loss: 1.9573\n",
      "Epoch 10/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3431 - loss: 1.8957 - val_accuracy: 0.3140 - val_loss: 1.9653\n",
      "Epoch 10/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3455 - loss: 1.8940 - val_accuracy: 0.3115 - val_loss: 1.9681\n",
      "Epoch 10/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3441 - loss: 1.8890 - val_accuracy: 0.3221 - val_loss: 1.9575\n",
      "Epoch 10/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3654 - loss: 1.8364 - val_accuracy: 0.3405 - val_loss: 1.9097\n",
      "Epoch 10/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3454 - loss: 1.8918 - val_accuracy: 0.3277 - val_loss: 1.9410\n",
      "Epoch 8/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3451 - loss: 1.8908 - val_accuracy: 0.3192 - val_loss: 1.9622\n",
      "Epoch 10/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3454 - loss: 1.8935 - val_accuracy: 0.3201 - val_loss: 1.9673\n",
      "Epoch 11/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3452 - loss: 1.8928 - val_accuracy: 0.3163 - val_loss: 1.9696\n",
      "Epoch 11/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3463 - loss: 1.8850 - val_accuracy: 0.3156 - val_loss: 1.9597\n",
      "Epoch 11/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3485 - loss: 1.8847 - val_accuracy: 0.3202 - val_loss: 1.9573\n",
      "Epoch 11/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3680 - loss: 1.8268 - val_accuracy: 0.3381 - val_loss: 1.9177\n",
      "Epoch 11/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3482 - loss: 1.8842 - val_accuracy: 0.3175 - val_loss: 1.9625\n",
      "Epoch 9/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3491 - loss: 1.8853 - val_accuracy: 0.3212 - val_loss: 1.9596\n",
      "Epoch 11/30\n",
      "391/391 - 5s - 13ms/step - accuracy: 0.3677 - loss: 1.8273 - val_accuracy: 0.3475 - val_loss: 1.8936\n",
      "Epoch 11/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3460 - loss: 1.8903 - val_accuracy: 0.3206 - val_loss: 1.9598\n",
      "Epoch 12/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3471 - loss: 1.8837 - val_accuracy: 0.3194 - val_loss: 1.9581\n",
      "Epoch 12/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3447 - loss: 1.8901 - val_accuracy: 0.3180 - val_loss: 1.9568\n",
      "Epoch 12/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3478 - loss: 1.8838 - val_accuracy: 0.3201 - val_loss: 1.9561\n",
      "Epoch 12/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3710 - loss: 1.8212 - val_accuracy: 0.3515 - val_loss: 1.8916\n",
      "Epoch 12/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3480 - loss: 1.8802 - val_accuracy: 0.3240 - val_loss: 1.9505\n",
      "Epoch 10/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3465 - loss: 1.8848 - val_accuracy: 0.3151 - val_loss: 1.9660\n",
      "Epoch 12/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3463 - loss: 1.8884 - val_accuracy: 0.3155 - val_loss: 1.9681\n",
      "Epoch 13/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3724 - loss: 1.8195 - val_accuracy: 0.3463 - val_loss: 1.8902\n",
      "Epoch 12/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3492 - loss: 1.8795 - val_accuracy: 0.3260 - val_loss: 1.9543\n",
      "Epoch 13/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3471 - loss: 1.8855 - val_accuracy: 0.3170 - val_loss: 1.9606\n",
      "Epoch 13/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3486 - loss: 1.8797 - val_accuracy: 0.3289 - val_loss: 1.9440\n",
      "Epoch 13/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3720 - loss: 1.8149 - val_accuracy: 0.3415 - val_loss: 1.8968\n",
      "Epoch 13/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3515 - loss: 1.8765 - val_accuracy: 0.3271 - val_loss: 1.9484\n",
      "Epoch 11/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3500 - loss: 1.8800 - val_accuracy: 0.3162 - val_loss: 1.9698\n",
      "Epoch 13/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3454 - loss: 1.8872 - val_accuracy: 0.3169 - val_loss: 1.9627\n",
      "Epoch 14/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3732 - loss: 1.8128 - val_accuracy: 0.3423 - val_loss: 1.8922\n",
      "Epoch 13/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3509 - loss: 1.8768 - val_accuracy: 0.3148 - val_loss: 1.9658\n",
      "Epoch 14/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3477 - loss: 1.8868 - val_accuracy: 0.3083 - val_loss: 1.9759\n",
      "Epoch 14/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3501 - loss: 1.8765 - val_accuracy: 0.3267 - val_loss: 1.9536\n",
      "Epoch 14/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3758 - loss: 1.8096 - val_accuracy: 0.3484 - val_loss: 1.8839\n",
      "Epoch 14/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3506 - loss: 1.8735 - val_accuracy: 0.3153 - val_loss: 1.9557\n",
      "Epoch 12/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3489 - loss: 1.8791 - val_accuracy: 0.3199 - val_loss: 1.9705\n",
      "Epoch 14/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3486 - loss: 1.8830 - val_accuracy: 0.3171 - val_loss: 1.9744\n",
      "Epoch 15/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3743 - loss: 1.8073 - val_accuracy: 0.3534 - val_loss: 1.8746\n",
      "Epoch 14/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3509 - loss: 1.8766 - val_accuracy: 0.3216 - val_loss: 1.9630\n",
      "Epoch 15/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3498 - loss: 1.8819 - val_accuracy: 0.3209 - val_loss: 1.9664\n",
      "Epoch 15/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3518 - loss: 1.8740 - val_accuracy: 0.3193 - val_loss: 1.9560\n",
      "Epoch 15/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3780 - loss: 1.8036 - val_accuracy: 0.3502 - val_loss: 1.8943\n",
      "Epoch 15/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3522 - loss: 1.8709 - val_accuracy: 0.3121 - val_loss: 1.9560\n",
      "Epoch 13/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3492 - loss: 1.8751 - val_accuracy: 0.3148 - val_loss: 1.9760\n",
      "Epoch 15/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3493 - loss: 1.8814 - val_accuracy: 0.3134 - val_loss: 1.9632\n",
      "Epoch 16/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3793 - loss: 1.8026 - val_accuracy: 0.3453 - val_loss: 1.8910\n",
      "Epoch 15/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3516 - loss: 1.8725 - val_accuracy: 0.3226 - val_loss: 1.9630\n",
      "Epoch 16/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3480 - loss: 1.8802 - val_accuracy: 0.3231 - val_loss: 1.9629\n",
      "Epoch 16/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3496 - loss: 1.8763 - val_accuracy: 0.3224 - val_loss: 1.9593\n",
      "Epoch 16/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3785 - loss: 1.7988 - val_accuracy: 0.3421 - val_loss: 1.8857\n",
      "Epoch 16/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3521 - loss: 1.8690 - val_accuracy: 0.3195 - val_loss: 1.9593\n",
      "Epoch 14/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3521 - loss: 1.8739 - val_accuracy: 0.3227 - val_loss: 1.9700\n",
      "Epoch 16/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3487 - loss: 1.8822 - val_accuracy: 0.3233 - val_loss: 1.9684\n",
      "Epoch 17/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3774 - loss: 1.7964 - val_accuracy: 0.3489 - val_loss: 1.8880\n",
      "Epoch 16/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3514 - loss: 1.8724 - val_accuracy: 0.3117 - val_loss: 1.9762\n",
      "Epoch 17/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3490 - loss: 1.8793 - val_accuracy: 0.3185 - val_loss: 1.9738\n",
      "Epoch 17/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3518 - loss: 1.8716 - val_accuracy: 0.3247 - val_loss: 1.9641\n",
      "Epoch 17/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3796 - loss: 1.7940 - val_accuracy: 0.3444 - val_loss: 1.8878\n",
      "Epoch 17/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3535 - loss: 1.8654 - val_accuracy: 0.3171 - val_loss: 1.9630\n",
      "Epoch 15/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3525 - loss: 1.8719 - val_accuracy: 0.3087 - val_loss: 1.9895\n",
      "Epoch 17/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3495 - loss: 1.8787 - val_accuracy: 0.3153 - val_loss: 1.9657\n",
      "Epoch 18/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3786 - loss: 1.7936 - val_accuracy: 0.3404 - val_loss: 1.8981\n",
      "Epoch 17/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3519 - loss: 1.8725 - val_accuracy: 0.3157 - val_loss: 1.9613\n",
      "Epoch 18/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3461 - loss: 1.8801 - val_accuracy: 0.3170 - val_loss: 1.9647\n",
      "Epoch 18/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3526 - loss: 1.8711 - val_accuracy: 0.3221 - val_loss: 1.9565\n",
      "Epoch 18/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3816 - loss: 1.7916 - val_accuracy: 0.3460 - val_loss: 1.8882\n",
      "Epoch 18/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3524 - loss: 1.8653 - val_accuracy: 0.3164 - val_loss: 1.9624\n",
      "Epoch 16/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3517 - loss: 1.8697 - val_accuracy: 0.3219 - val_loss: 1.9659\n",
      "Epoch 18/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3507 - loss: 1.8771 - val_accuracy: 0.3118 - val_loss: 1.9755\n",
      "Epoch 19/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3818 - loss: 1.7903 - val_accuracy: 0.3558 - val_loss: 1.8731\n",
      "Epoch 18/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3536 - loss: 1.8690 - val_accuracy: 0.3184 - val_loss: 1.9795\n",
      "Epoch 19/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3495 - loss: 1.8778 - val_accuracy: 0.3186 - val_loss: 1.9728\n",
      "Epoch 19/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3529 - loss: 1.8694 - val_accuracy: 0.3143 - val_loss: 1.9658\n",
      "Epoch 19/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3831 - loss: 1.7875 - val_accuracy: 0.3513 - val_loss: 1.8773\n",
      "Epoch 19/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3555 - loss: 1.8616 - val_accuracy: 0.3140 - val_loss: 1.9458\n",
      "Epoch 17/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3526 - loss: 1.8698 - val_accuracy: 0.3147 - val_loss: 1.9769\n",
      "Epoch 19/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3510 - loss: 1.8750 - val_accuracy: 0.3201 - val_loss: 1.9692\n",
      "Epoch 20/30\n",
      "391/391 - 3s - 8ms/step - accuracy: 0.3832 - loss: 1.7837 - val_accuracy: 0.3497 - val_loss: 1.8797\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3528 - loss: 1.8708 - val_accuracy: 0.3210 - val_loss: 1.9780\n",
      "Epoch 20/30\n",
      "Epoch 19/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3520 - loss: 1.8751 - val_accuracy: 0.3161 - val_loss: 1.9850\n",
      "Epoch 20/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3552 - loss: 1.8687 - val_accuracy: 0.3157 - val_loss: 1.9725\n",
      "Epoch 20/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3835 - loss: 1.7842 - val_accuracy: 0.3498 - val_loss: 1.8687\n",
      "Epoch 20/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3551 - loss: 1.8635 - val_accuracy: 0.3155 - val_loss: 1.9553\n",
      "Epoch 18/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3514 - loss: 1.8688 - val_accuracy: 0.3155 - val_loss: 1.9901\n",
      "Epoch 20/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3835 - loss: 1.7819 - val_accuracy: 0.3580 - val_loss: 1.8701\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3537 - loss: 1.8685 - val_accuracy: 0.3188 - val_loss: 1.9779\n",
      "Epoch 20/30\n",
      "Epoch 21/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3503 - loss: 1.8747 - val_accuracy: 0.3079 - val_loss: 1.9894\n",
      "Epoch 21/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3537 - loss: 1.8662 - val_accuracy: 0.3174 - val_loss: 1.9623\n",
      "Epoch 21/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3860 - loss: 1.7816 - val_accuracy: 0.3526 - val_loss: 1.8724\n",
      "Epoch 21/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3548 - loss: 1.8615 - val_accuracy: 0.3145 - val_loss: 1.9594\n",
      "Epoch 19/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3525 - loss: 1.8669 - val_accuracy: 0.3213 - val_loss: 1.9727\n",
      "Epoch 21/30\n",
      "391/391 - 5s - 12ms/step - accuracy: 0.3517 - loss: 1.8748 - val_accuracy: 0.3070 - val_loss: 1.9879\n",
      "Epoch 21/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3537 - loss: 1.8660 - val_accuracy: 0.3137 - val_loss: 1.9768\n",
      "Epoch 22/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3851 - loss: 1.7791 - val_accuracy: 0.3530 - val_loss: 1.8796\n",
      "Epoch 21/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3511 - loss: 1.8741 - val_accuracy: 0.3208 - val_loss: 1.9737\n",
      "Epoch 22/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3512 - loss: 1.8685 - val_accuracy: 0.3188 - val_loss: 1.9547\n",
      "Epoch 22/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3856 - loss: 1.7781 - val_accuracy: 0.3517 - val_loss: 1.8825\n",
      "Epoch 22/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3562 - loss: 1.8593 - val_accuracy: 0.3198 - val_loss: 1.9622\n",
      "Epoch 20/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3549 - loss: 1.8663 - val_accuracy: 0.3134 - val_loss: 1.9798\n",
      "Epoch 22/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3518 - loss: 1.8738 - val_accuracy: 0.3188 - val_loss: 1.9745\n",
      "Epoch 22/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3534 - loss: 1.8649 - val_accuracy: 0.3130 - val_loss: 1.9839\n",
      "Epoch 23/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3503 - loss: 1.8728 - val_accuracy: 0.3067 - val_loss: 1.9904\n",
      "Epoch 23/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3879 - loss: 1.7767 - val_accuracy: 0.3572 - val_loss: 1.8645\n",
      "Epoch 22/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3528 - loss: 1.8662 - val_accuracy: 0.3222 - val_loss: 1.9592\n",
      "Epoch 23/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3879 - loss: 1.7746 - val_accuracy: 0.3563 - val_loss: 1.8709\n",
      "Epoch 23/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3567 - loss: 1.8587 - val_accuracy: 0.3132 - val_loss: 1.9652\n",
      "Epoch 21/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3548 - loss: 1.8643 - val_accuracy: 0.3169 - val_loss: 1.9701\n",
      "Epoch 23/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3510 - loss: 1.8748 - val_accuracy: 0.3132 - val_loss: 1.9710\n",
      "Epoch 23/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3563 - loss: 1.8643 - val_accuracy: 0.3095 - val_loss: 1.9768\n",
      "Epoch 24/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3513 - loss: 1.8721 - val_accuracy: 0.3079 - val_loss: 1.9791\n",
      "Epoch 24/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3862 - loss: 1.7731 - val_accuracy: 0.3586 - val_loss: 1.8679\n",
      "Epoch 23/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3524 - loss: 1.8646 - val_accuracy: 0.3193 - val_loss: 1.9649\n",
      "Epoch 24/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3866 - loss: 1.7735 - val_accuracy: 0.3561 - val_loss: 1.8724\n",
      "Epoch 24/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3545 - loss: 1.8600 - val_accuracy: 0.3174 - val_loss: 1.9709\n",
      "Epoch 22/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3540 - loss: 1.8636 - val_accuracy: 0.3242 - val_loss: 1.9725\n",
      "Epoch 24/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3545 - loss: 1.8727 - val_accuracy: 0.3134 - val_loss: 1.9737\n",
      "Epoch 24/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3555 - loss: 1.8648 - val_accuracy: 0.3151 - val_loss: 1.9768\n",
      "Epoch 25/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3521 - loss: 1.8707 - val_accuracy: 0.3128 - val_loss: 1.9947\n",
      "Epoch 25/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3886 - loss: 1.7702 - val_accuracy: 0.3561 - val_loss: 1.8701\n",
      "Epoch 24/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3552 - loss: 1.8624 - val_accuracy: 0.3197 - val_loss: 1.9593\n",
      "Epoch 25/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3887 - loss: 1.7710 - val_accuracy: 0.3552 - val_loss: 1.8806\n",
      "Epoch 25/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3555 - loss: 1.8573 - val_accuracy: 0.3151 - val_loss: 1.9648\n",
      "Epoch 23/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3553 - loss: 1.8629 - val_accuracy: 0.3164 - val_loss: 1.9820\n",
      "Epoch 25/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3510 - loss: 1.8733 - val_accuracy: 0.3174 - val_loss: 1.9789\n",
      "Epoch 25/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3556 - loss: 1.8651 - val_accuracy: 0.3151 - val_loss: 1.9836\n",
      "Epoch 26/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3510 - loss: 1.8712 - val_accuracy: 0.3203 - val_loss: 1.9757\n",
      "Epoch 26/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3893 - loss: 1.7691 - val_accuracy: 0.3620 - val_loss: 1.8669\n",
      "Epoch 25/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3546 - loss: 1.8643 - val_accuracy: 0.3089 - val_loss: 1.9674\n",
      "Epoch 26/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3565 - loss: 1.8558 - val_accuracy: 0.3138 - val_loss: 1.9687\n",
      "Epoch 24/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3895 - loss: 1.7689 - val_accuracy: 0.3587 - val_loss: 1.8683\n",
      "Epoch 26/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3542 - loss: 1.8620 - val_accuracy: 0.3154 - val_loss: 1.9788\n",
      "Epoch 26/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3517 - loss: 1.8702 - val_accuracy: 0.3092 - val_loss: 1.9791\n",
      "Epoch 26/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3560 - loss: 1.8612 - val_accuracy: 0.3179 - val_loss: 1.9899\n",
      "Epoch 27/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3509 - loss: 1.8702 - val_accuracy: 0.3081 - val_loss: 1.9887\n",
      "Epoch 27/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3897 - loss: 1.7661 - val_accuracy: 0.3565 - val_loss: 1.8718\n",
      "Epoch 26/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3560 - loss: 1.8615 - val_accuracy: 0.3138 - val_loss: 1.9726\n",
      "Epoch 27/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3581 - loss: 1.8528 - val_accuracy: 0.3184 - val_loss: 1.9616\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3893 - loss: 1.7663 - val_accuracy: 0.3522 - val_loss: 1.8703\n",
      "Epoch 25/30\n",
      "Epoch 27/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3547 - loss: 1.8614 - val_accuracy: 0.3089 - val_loss: 1.9836\n",
      "Epoch 27/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3533 - loss: 1.8685 - val_accuracy: 0.3107 - val_loss: 1.9818\n",
      "Epoch 27/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3570 - loss: 1.8635 - val_accuracy: 0.3022 - val_loss: 1.9989\n",
      "Epoch 28/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3539 - loss: 1.8707 - val_accuracy: 0.3080 - val_loss: 1.9842\n",
      "Epoch 28/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3542 - loss: 1.8620 - val_accuracy: 0.3256 - val_loss: 1.9661\n",
      "Epoch 28/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3922 - loss: 1.7637 - val_accuracy: 0.3571 - val_loss: 1.8698\n",
      "Epoch 27/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3585 - loss: 1.8527 - val_accuracy: 0.3146 - val_loss: 1.9683\n",
      "Epoch 26/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3905 - loss: 1.7661 - val_accuracy: 0.3555 - val_loss: 1.8829\n",
      "Epoch 28/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3563 - loss: 1.8600 - val_accuracy: 0.3090 - val_loss: 1.9924\n",
      "Epoch 28/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3526 - loss: 1.8678 - val_accuracy: 0.3170 - val_loss: 1.9744\n",
      "Epoch 28/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3562 - loss: 1.8617 - val_accuracy: 0.3041 - val_loss: 2.0075\n",
      "Epoch 29/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3516 - loss: 1.8682 - val_accuracy: 0.3114 - val_loss: 1.9872\n",
      "Epoch 29/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3557 - loss: 1.8598 - val_accuracy: 0.3090 - val_loss: 1.9737\n",
      "Epoch 29/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3913 - loss: 1.7625 - val_accuracy: 0.3565 - val_loss: 1.8723\n",
      "Epoch 28/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3577 - loss: 1.8532 - val_accuracy: 0.3152 - val_loss: 1.9701\n",
      "Epoch 27/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3898 - loss: 1.7637 - val_accuracy: 0.3562 - val_loss: 1.8685\n",
      "Epoch 29/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3573 - loss: 1.8600 - val_accuracy: 0.3185 - val_loss: 1.9903\n",
      "Epoch 29/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3535 - loss: 1.8706 - val_accuracy: 0.3143 - val_loss: 1.9722\n",
      "Epoch 29/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3529 - loss: 1.8667 - val_accuracy: 0.3107 - val_loss: 1.9938\n",
      "Epoch 30/30\n",
      "391/391 - 3s - 7ms/step - accuracy: 0.3567 - loss: 1.8613 - val_accuracy: 0.3047 - val_loss: 1.9913\n",
      "Epoch 30/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3536 - loss: 1.8590 - val_accuracy: 0.3100 - val_loss: 1.9714\n",
      "Epoch 30/30\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3924 - loss: 1.7602 - val_accuracy: 0.3586 - val_loss: 1.8714\n",
      "Epoch 29/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3570 - loss: 1.8538 - val_accuracy: 0.3188 - val_loss: 1.9624\n",
      "Epoch 28/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3901 - loss: 1.7633 - val_accuracy: 0.3579 - val_loss: 1.8729\n",
      "Epoch 30/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3534 - loss: 1.8607 - val_accuracy: 0.3106 - val_loss: 1.9865\n",
      "Epoch 30/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3525 - loss: 1.8686 - val_accuracy: 0.3071 - val_loss: 1.9825\n",
      "Epoch 30/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3521 - loss: 1.8661 - val_accuracy: 0.3113 - val_loss: 1.9817\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3553 - loss: 1.8605 - val_accuracy: 0.3109 - val_loss: 1.9845\n",
      "391/391 - 3s - 6ms/step - accuracy: 0.3563 - loss: 1.8602 - val_accuracy: 0.3123 - val_loss: 1.9690\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3957 - loss: 1.7586 - val_accuracy: 0.3535 - val_loss: 1.8714\n",
      "Epoch 30/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3584 - loss: 1.8529 - val_accuracy: 0.3134 - val_loss: 1.9760\n",
      "Epoch 29/30\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3920 - loss: 1.7606 - val_accuracy: 0.3599 - val_loss: 1.8627\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3549 - loss: 1.8609 - val_accuracy: 0.3098 - val_loss: 1.9837\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3531 - loss: 1.8684 - val_accuracy: 0.3100 - val_loss: 1.9805\n",
      "391/391 - 2s - 6ms/step - accuracy: 0.3946 - loss: 1.7570 - val_accuracy: 0.3587 - val_loss: 1.8709\n",
      "391/391 - 2s - 5ms/step - accuracy: 0.3585 - loss: 1.8511 - val_accuracy: 0.3065 - val_loss: 1.9728\n",
      "Epoch 30/30\n",
      "391/391 - 1s - 4ms/step - accuracy: 0.3620 - loss: 1.8499 - val_accuracy: 0.3120 - val_loss: 1.9679\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for j in range(3):\n",
    "    with ProcessPoolExecutor(8) as executor:\n",
    "        runner = {\n",
    "            executor.submit(model,variant = p, tr_layer = train_layer, te_layer= test_layer): p for p in permutations[8*j:8*(j+1)]\n",
    "        }\n",
    "        for future in as_completed(runner):\n",
    "            runner.pop(future)\n",
    "# 1 min 8 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96b6663",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QML-QPF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
