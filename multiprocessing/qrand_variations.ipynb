{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 01:48:41.398203: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-05 01:48:42.047600: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from datetime import datetime\n",
    "import pathlib\n",
    "import os\n",
    "import gc\n",
    "from core import Model\n",
    "import numpy as np\n",
    "import math\n",
    "from itertools import permutations\n",
    "\n",
    "os.environ['CUDA_​DEVICE_​ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "#clock_start = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "clock_start = \"20240804-171809\"\n",
    "workdir = str(pathlib.Path().resolve())\n",
    "\n",
    "\n",
    "cnot_variations= np.asarray([[19,0], [23,0], [29,0] , [31,0], [37,0], [41,0], [43,0], [47,0]])\n",
    "ent_variations = [(1,0), (2,0), (3,0), (5,0), (7,0), (11,0), (13,0), (17,0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def frontload_data():\n",
    "    from tensorflow import keras\n",
    "    mnist_dataset = keras.datasets.fashion_mnist\n",
    "    (train_images, train_labels), (test_images, test_labels) = mnist_dataset.load_data()\n",
    "    mnist_dataset = keras.datasets.mnist\n",
    "    (train_images, train_labels), (test_images, test_labels) = mnist_dataset.load_data()\n",
    "\n",
    "def pool_job(input):\n",
    "    this_model = Model(*input)\n",
    "    this_model.set_data()\n",
    "    #this_model.prep()\n",
    "    this_model.prep_qrand_variant(input[-2],input[-1])\n",
    "    this_model.pre_filter()\n",
    "    this_model.fit()\n",
    "    this_model.save_filtered()\n",
    "\n",
    "#to prevent race condition\n",
    "frontload_data()\n",
    "\n",
    "for cnot_var in cnot_variations:\n",
    "    with ProcessPoolExecutor(8) as executor:\n",
    "        runner = {\n",
    "                executor.submit(pool_job, (1,2,clock_start,workdir,cnot_var,m)): m for m in ent_variations\n",
    "            }\n",
    "        for future in as_completed(runner):\n",
    "            runner.pop(future)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pool_job((1,2,clock_start,workdir,cnot_variations[0],ent_variations[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 01:49:10.411512: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 01:49:10.411589: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 01:49:10.413611: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 01:49:10.413757: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 01:49:10.413850: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 01:49:10.414056: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 01:49:10.414072: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 01:49:10.414212: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 01:49:10.414230: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 01:49:10.414452: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 01:49:10.414794: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 01:49:10.414987: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 01:49:10.415028: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 01:49:10.415202: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 01:49:10.416719: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 01:49:10.416782: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 01:49:10.433865: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 01:49:10.435077: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 01:49:10.435545: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 01:49:10.437501: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 01:49:10.437942: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 01:49:10.439538: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 01:49:10.440909: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 01:49:10.441185: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 01:49:10.448345: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 01:49:10.448452: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 01:49:10.453618: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 01:49:10.453733: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 01:49:10.458081: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 01:49:10.458218: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 01:49:10.462040: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 01:49:10.462150: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 01:49:10.465688: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 01:49:10.465832: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 01:49:10.466894: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 01:49:10.466894: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 01:49:10.467031: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 01:49:10.467030: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 01:49:10.467680: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 01:49:10.467817: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 01:49:11.035267: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 01:49:11.035356: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 01:49:11.035921: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 01:49:11.036072: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 01:49:11.039017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6427 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 01:49:11.039423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6427 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 01:49:11.040397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6427 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 01:49:11.040629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6427 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 01:49:11.126628: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 01:49:11.127109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6173 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 01:49:11.191666: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 01:49:11.192515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5969 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 01:49:11.202632: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 01:49:11.202936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5865 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 01:49:11.208438: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 01:49:11.208911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5865 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722822551.488117    1494 service.cc:145] XLA service 0x729058002890 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722822551.488162    1494 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 01:49:11.497220: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722822551.500457    1509 service.cc:145] XLA service 0x7290540141c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722822551.500506    1509 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 01:49:11.510323: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722822551.518207    1479 service.cc:145] XLA service 0x72905c003230 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722822551.518273    1479 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722822551.522272    1475 service.cc:145] XLA service 0x72905c002890 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722822551.522317    1475 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 01:49:11.530796: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 01:49:11.531020: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 01:49:11.547183: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-08-05 01:49:11.557992: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-08-05 01:49:11.567997: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-08-05 01:49:11.578520: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722822551.632563    1546 service.cc:145] XLA service 0x729054003430 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722822551.632606    1546 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722822551.634206    1575 service.cc:145] XLA service 0x729054003d60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722822551.634247    1575 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 01:49:11.641591: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 01:49:11.641626: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 01:49:11.683823: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-08-05 01:49:11.686860: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:00\u001b[0m 385ms/step/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722822551.688864    1531 service.cc:145] XLA service 0x729048004000 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722822551.688901    1531 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 01:49:11.697772: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 01:49:11.748239: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "I0000 00:00:1722822551.750223    1494 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722822551.753526    1509 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722822551.758584    1560 service.cc:145] XLA service 0x729050002c40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722822551.758628    1560 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "I0000 00:00:1722822551.765842    1479 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722822551.766809    1475 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-08-05 01:49:11.767086: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 01:49:11.809025: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "I0000 00:00:1722822551.864834    1546 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722822551.873362    1575 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m103/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1722822551.929461    1531 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722822551.971728    1560 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot19-0--1-0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot19-0--2-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot19-0--17-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot19-0--3-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot19-0--5-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot19-0--11-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot19-0--7-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot19-0--13-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot19-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot19-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot19-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot19-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot19-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot19-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot19-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot19-0--13-0.gif\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7edfd00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7e9e830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7d3a950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7ec1f30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7ec0af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7edbd00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7d0fa30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7efb2e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7d3a950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7d5a050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7e8f250> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7e9e830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7ead870> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7ec0af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7ee9510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7d1b2e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot19-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot19-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot19-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot19-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot19-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot19-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot19-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot19-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot19-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot19-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot19-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot19-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot19-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot19-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot19-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot19-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot19-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot19-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot19-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot19-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot19-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot19-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot19-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot19-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot19-0--17-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot19-0--17-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot19-0--5-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot19-0--5-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot19-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot19-0--3-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot19-0--3-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot19-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot19-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot19-0--2-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot19-0--2-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot19-0--11-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot19-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot19-0--11-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot19-0--7-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot19-0--7-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot19-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot19-0--1-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot19-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot19-0--1-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot19-0--13-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot19-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot19-0--13-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot19-0--13-0.gif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 01:54:08.473180: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 01:54:08.473278: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 01:54:08.474404: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 01:54:08.474494: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 01:54:08.474918: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 01:54:08.474895: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 01:54:08.475006: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 01:54:08.474906: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 01:54:08.475039: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 01:54:08.475089: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 01:54:08.476187: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 01:54:08.476387: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 01:54:08.476441: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 01:54:08.476479: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 01:54:08.476624: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 01:54:08.476666: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 01:54:08.507085: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 01:54:08.507207: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 01:54:08.507387: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 01:54:08.507582: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 01:54:08.507927: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 01:54:08.508221: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 01:54:08.508555: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 01:54:08.508849: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 01:54:08.528046: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 01:54:08.528183: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 01:54:08.530087: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 01:54:08.530225: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 01:54:08.530244: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 01:54:08.530399: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 01:54:08.531789: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 01:54:08.531965: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 01:54:08.536719: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 01:54:08.536864: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 01:54:08.536890: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 01:54:08.536906: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 01:54:08.536907: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 01:54:08.537035: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 01:54:08.537045: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 01:54:08.537062: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 01:54:09.035139: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 01:54:09.035744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6753 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 01:54:09.154470: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 01:54:09.156813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6489 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 01:54:09.195726: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 01:54:09.198695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6465 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 01:54:09.219849: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 01:54:09.221366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6351 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 01:54:09.244764: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 01:54:09.245604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6241 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 01:54:09.263751: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 01:54:09.264089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5989 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 01:54:09.278671: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 01:54:09.278997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5897 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 01:54:09.299797: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 01:54:09.300839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6021 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722822852.484258    3630 service.cc:145] XLA service 0x729058014ed0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722822852.484372    3630 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 01:54:12.504310: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 01:54:12.543807: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m111/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1722822852.693869    3630 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722822852.893496    3673 service.cc:145] XLA service 0x72904c0141e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722822852.893537    3673 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:46\u001b[0m 342ms/step/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 01:54:12.901084: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722822852.922720    3689 service.cc:145] XLA service 0x72904c015340 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722822852.922766    3689 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 01:54:12.931233: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 01:54:12.938869: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-08-05 01:54:12.976591: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722822853.004866    3703 service.cc:145] XLA service 0x72904c003d60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722822853.004912    3703 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722822853.011683    3766 service.cc:145] XLA service 0x729058003f50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722822853.011728    3766 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722822853.014230    3722 service.cc:145] XLA service 0x72904c003d60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722822853.014274    3722 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 01:54:13.014627: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722822853.016024    3751 service.cc:145] XLA service 0x72904c014aa0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722822853.016057    3751 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722822853.016519    3737 service.cc:145] XLA service 0x729048014870 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722822853.016554    3737 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 01:54:13.021896: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 01:54:13.021987: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 01:54:13.023682: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 01:54:13.043147: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 01:54:13.056651: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-08-05 01:54:13.065143: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-08-05 01:54:13.067494: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "I0000 00:00:1722822853.079832    3673 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-08-05 01:54:13.083134: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "I0000 00:00:1722822853.092400    3689 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-08-05 01:54:13.092898: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m142/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1722822853.301862    3751 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722822853.341345    3703 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722822853.350895    3722 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722822853.357771    3766 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722822853.361575    3737 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m142/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot23-0--7-0.png\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot23-0--1-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot23-0--13-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot23-0--2-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot23-0--11-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot23-0--17-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot23-0--5-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot23-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot23-0--3-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot23-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot23-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot23-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot23-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot23-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot23-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot23-0--5-0.gif\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7d1fa30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7d6e050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7eaa830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7ef1510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7eccaf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7d1f2e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7eae830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7eccaf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7e6b1c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7e971c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7eb1a20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7eb57e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7eba830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7ed8af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7ef5510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7d272e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot23-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot23-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot23-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot23-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot23-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot23-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot23-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot23-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot23-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot23-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot23-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot23-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot23-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot23-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot23-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot23-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot23-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot23-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot23-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot23-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot23-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot23-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot23-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot23-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot23-0--2-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot23-0--2-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot23-0--5-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot23-0--5-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot23-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot23-0--13-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot23-0--13-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot23-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot23-0--7-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot23-0--7-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot23-0--17-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot23-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot23-0--17-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot23-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot23-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot23-0--11-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot23-0--3-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot23-0--3-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot23-0--11-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot23-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot23-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot23-0--1-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot23-0--1-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot23-0--1-0.gif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 01:59:04.683667: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 01:59:04.683747: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 01:59:04.685199: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 01:59:04.685349: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 01:59:04.686007: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 01:59:04.686056: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 01:59:04.686219: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 01:59:04.686106: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 01:59:04.686261: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 01:59:04.686317: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 01:59:04.686560: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 01:59:04.686707: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 01:59:04.686887: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 01:59:04.687077: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 01:59:04.688323: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 01:59:04.688508: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 01:59:04.713308: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 01:59:04.713780: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 01:59:04.714521: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 01:59:04.715075: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 01:59:04.715441: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 01:59:04.715700: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 01:59:04.716130: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 01:59:04.716479: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 01:59:04.735102: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 01:59:04.735235: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 01:59:04.735875: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 01:59:04.736007: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 01:59:04.738555: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 01:59:04.738716: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 01:59:04.740572: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 01:59:04.740821: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 01:59:04.744205: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 01:59:04.744319: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 01:59:04.744355: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 01:59:04.744440: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 01:59:04.744442: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 01:59:04.744499: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 01:59:04.744582: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 01:59:04.744649: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 01:59:05.303316: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 01:59:05.305448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6599 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 01:59:05.355870: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 01:59:05.355902: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 01:59:05.360196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6425 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 01:59:05.361015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6425 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 01:59:05.394598: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 01:59:05.397632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6383 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 01:59:05.425268: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 01:59:05.425667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6021 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 01:59:05.428995: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 01:59:05.429428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6021 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 01:59:05.467071: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 01:59:05.467657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6021 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 01:59:05.473470: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 01:59:05.473765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5833 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722823148.576278    5815 service.cc:145] XLA service 0x729054003040 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722823148.576358    5815 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 01:59:08.592360: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 01:59:08.628069: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "I0000 00:00:1722823148.761237    5815 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:48\u001b[0m 348ms/step/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722823149.047704    5842 service.cc:145] XLA service 0x72904c003590 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722823149.047752    5842 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 01:59:09.057471: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722823149.086683    5866 service.cc:145] XLA service 0x72904c015330 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722823149.086737    5866 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 01:59:09.097997: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 01:59:09.104048: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722823149.104683    5846 service.cc:145] XLA service 0x729058003f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722823149.104727    5846 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 01:59:09.111019: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 01:59:09.137196: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722823149.138675    5913 service.cc:145] XLA service 0x729054003d60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722823149.138719    5913 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722823149.141833    5898 service.cc:145] XLA service 0x729058003d60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722823149.141879    5898 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 01:59:09.147051: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722823149.147937    5927 service.cc:145] XLA service 0x729054003430 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722823149.147976    5927 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 01:59:09.149762: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-08-05 01:59:09.150982: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722823149.155132    5882 service.cc:145] XLA service 0x72904c014cf0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722823149.155179    5882 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 01:59:09.157120: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 01:59:09.164492: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 01:59:09.197929: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-08-05 01:59:09.201459: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-08-05 01:59:09.206994: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-08-05 01:59:09.214696: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "I0000 00:00:1722823149.237345    5842 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:32\u001b[0m 488ms/step/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1722823149.326275    5866 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722823149.344233    5846 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722823149.478248    5898 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722823149.484056    5927 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722823149.484056    5913 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722823149.487867    5882 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m233/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot29-0--5-0.png\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot29-0--2-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot29-0--1-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot29-0--13-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot29-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot29-0--17-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot29-0--7-0.png/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot29-0--11-0.png\n",
      "\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot29-0--3-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot29-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot29-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot29-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot29-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot29-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot29-0--11-0.gif\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7e7b250> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7ec5ab0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot29-0--7-0.gif\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7ed9fc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7d0b370> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7ecdfc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7eefa30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7d07370> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7ecdf30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7d4aa70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7ef3a30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7d032e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7ee7c70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7d4ea70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7d429e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7ef9630> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7d2f400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot29-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot29-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot29-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot29-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot29-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot29-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot29-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot29-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot29-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot29-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot29-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot29-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot29-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot29-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot29-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot29-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot29-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot29-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot29-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot29-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot29-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot29-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot29-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot29-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot29-0--7-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot29-0--7-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot29-0--3-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot29-0--5-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot29-0--3-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot29-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot29-0--5-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot29-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot29-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot29-0--13-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot29-0--11-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot29-0--13-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot29-0--11-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot29-0--2-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot29-0--2-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot29-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot29-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot29-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot29-0--1-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot29-0--17-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot29-0--1-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot29-0--17-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot29-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot29-0--1-0.gif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 02:04:03.376880: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:04:03.376973: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:04:03.377226: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:04:03.377285: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:04:03.377398: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:04:03.377545: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:04:03.378067: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:04:03.378278: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:04:03.378296: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:04:03.378533: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:04:03.378661: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:04:03.378815: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:04:03.379417: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:04:03.379617: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:04:03.379696: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:04:03.379886: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:04:03.411704: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:04:03.411815: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:04:03.412139: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:04:03.412366: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:04:03.412574: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:04:03.412975: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:04:03.413433: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:04:03.414093: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:04:03.432730: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:04:03.432849: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:04:03.433952: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:04:03.434073: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:04:03.434630: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:04:03.434762: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:04:03.435245: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:04:03.435392: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:04:03.443854: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:04:03.444028: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:04:03.444349: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:04:03.444494: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:04:03.444566: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:04:03.444715: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:04:03.445199: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:04:03.445319: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:04:04.007936: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:04:04.011711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6601 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:04:04.058976: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:04:04.060651: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:04:04.062583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6517 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:04:04.063331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6517 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:04:04.117019: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:04:04.119697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6331 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:04:04.148792: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:04:04.149438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6115 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:04:04.155508: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:04:04.156016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6081 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:04:04.166901: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:04:04.167218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5897 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:04:04.231063: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:04:04.231494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5897 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 43/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722823444.514780    7996 service.cc:145] XLA service 0x729054003500 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722823444.514816    7996 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 02:04:04.522505: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722823444.546784    8026 service.cc:145] XLA service 0x729054014ef0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722823444.546862    8026 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 02:04:04.552664: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722823444.559964    8047 service.cc:145] XLA service 0x72904c015480 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722823444.560007    8047 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 02:04:04.566551: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 02:04:04.567380: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722823444.585948    8090 service.cc:145] XLA service 0x729054003120 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722823444.585990    8090 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 02:04:04.594498: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 02:04:04.600211: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722823444.605306    8076 service.cc:145] XLA service 0x729050003210 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722823444.605356    8076 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 02:04:04.618785: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722823444.622206    8109 service.cc:145] XLA service 0x729050003430 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722823444.622246    8109 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 02:04:04.623741: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-08-05 02:04:04.632374: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-08-05 02:04:04.635406: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1722823444.654563    7996 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-08-05 02:04:04.658173: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-08-05 02:04:04.678965: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "I0000 00:00:1722823444.714161    8047 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m265/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1722823444.830136    8026 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722823444.830372    8090 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722823444.858565    8076 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722823444.862729    8109 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722823444.925520    8016 service.cc:145] XLA service 0x729044014c80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722823444.925561    8016 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 02:04:04.935235: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 02:04:04.987741: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m130/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1722823445.144188    8016 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722823445.178356    8063 service.cc:145] XLA service 0x729058003f60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722823445.178404    8063 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 02:04:05.186807: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 02:04:05.232561: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m226/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1722823445.434090    8063 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m206/313\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 987us/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot31-0--1-0.png\n",
      "\u001b[1m257/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 987us/step/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot31-0--13-0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m301/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  /workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot31-0--11-0.png\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot31-0--5-0.png/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot31-0--3-0.png\n",
      "\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot31-0--17-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot31-0--1-0.gif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot31-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot31-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot31-0--7-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot31-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot31-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot31-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot31-0--2-0.png\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7e97250> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7eb5870> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7d477f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot31-0--7-0.gif\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7d91750> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot31-0--2-0.gif\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7e8b2e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7ea9900> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7ea32e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7ec1900> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7eebc70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7ecdfc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7d469e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7d07370> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7e8b250> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7ea9870> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7e38b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7e9a3b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot31-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot31-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot31-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot31-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot31-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot31-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot31-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot31-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot31-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot31-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot31-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot31-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot31-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot31-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot31-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot31-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot31-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot31-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot31-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot31-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot31-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot31-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot31-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot31-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot31-0--1-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot31-0--1-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot31-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot31-0--17-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot31-0--17-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot31-0--5-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot31-0--5-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot31-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot31-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot31-0--7-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot31-0--7-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot31-0--11-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot31-0--11-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot31-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot31-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot31-0--3-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot31-0--3-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot31-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot31-0--13-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot31-0--13-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot31-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot31-0--2-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot31-0--2-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot31-0--2-0.gif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 02:09:03.067814: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:09:03.067908: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:09:03.068875: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:09:03.068952: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:09:03.069405: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:09:03.069586: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:09:03.069894: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:09:03.070036: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:09:03.070076: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:09:03.070110: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:09:03.070285: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:09:03.070314: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:09:03.071139: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:09:03.071311: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:09:03.071911: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:09:03.072114: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:09:03.089882: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:09:03.090083: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:09:03.090455: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:09:03.090912: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:09:03.095464: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:09:03.095778: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:09:03.096182: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:09:03.096536: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:09:03.108099: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:09:03.108225: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:09:03.110133: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:09:03.110330: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:09:03.112781: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:09:03.112782: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:09:03.112932: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:09:03.112957: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:09:03.121270: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:09:03.121270: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:09:03.121448: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:09:03.121490: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:09:03.121540: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:09:03.121540: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:09:03.121684: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:09:03.121689: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:09:03.676678: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:09:03.677776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6611 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:09:03.702357: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:09:03.706604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6435 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:09:03.724910: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:09:03.728074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6611 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:09:03.729304: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:09:03.731522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6425 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:09:03.817975: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:09:03.818819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6175 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:09:03.844018: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:09:03.844540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5897 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:09:03.846670: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:09:03.847348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5897 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:09:03.877673: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:09:03.878328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5865 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:28\u001b[0m 284ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722823744.163416   10251 service.cc:145] XLA service 0x72904c003d70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722823744.163455   10251 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 02:09:04.169230: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722823744.177425   10203 service.cc:145] XLA service 0x729054014e50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722823744.177474   10203 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 02:09:04.186522: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 02:09:04.214296: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722823744.215510   10235 service.cc:145] XLA service 0x72905c002890 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722823744.215594   10235 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722823744.216203   10221 service.cc:145] XLA service 0x729058003120 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722823744.216242   10221 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 02:09:04.224685: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 02:09:04.224877: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 02:09:04.233221: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-08-05 02:09:04.270651: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-08-05 02:09:04.273888: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722823744.295635   10287 service.cc:145] XLA service 0x729054002710 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722823744.295697   10287 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 02:09:04.305701: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722823744.322790   10299 service.cc:145] XLA service 0x729054002890 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722823744.322829   10299 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "I0000 00:00:1722823744.331123   10251 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-08-05 02:09:04.332557: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722823744.338705   10271 service.cc:145] XLA service 0x729058003f60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722823744.338749   10271 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 02:09:04.347671: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 02:09:04.350728: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722823744.354585   10319 service.cc:145] XLA service 0x729058003f60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722823744.354629   10319 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 02:09:04.363142: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 47/313\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1722823744.365059   10203 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-08-05 02:09:04.375654: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-08-05 02:09:04.394889: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-08-05 02:09:04.409147: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "I0000 00:00:1722823744.432779   10235 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722823744.443147   10221 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722823744.528134   10287 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m266/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1722823744.606819   10299 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722823744.639494   10271 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722823744.642808   10319 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot37-0--17-0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot37-0--11-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot37-0--2-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot37-0--5-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot37-0--7-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot37-0--3-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot37-0--13-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot37-0--1-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot37-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot37-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot37-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot37-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot37-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot37-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot37-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot37-0--1-0.gif\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7e731c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7e73250> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7eb9a20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7ebdab0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7ec9f30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7d032e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7e932e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7eb5900> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7eeba30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7d4aa70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7ef1630> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7d27400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7ee7a30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7ef3c70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7d42a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7d4e9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot37-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot37-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot37-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot37-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot37-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot37-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot37-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot37-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot37-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot37-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot37-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot37-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot37-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot37-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot37-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot37-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot37-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot37-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot37-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot37-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot37-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot37-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot37-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot37-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot37-0--13-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot37-0--13-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot37-0--1-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot37-0--1-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot37-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot37-0--5-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot37-0--5-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot37-0--2-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot37-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot37-0--2-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot37-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot37-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot37-0--17-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot37-0--17-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot37-0--11-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot37-0--11-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot37-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot37-0--3-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot37-0--3-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot37-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot37-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot37-0--7-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot37-0--7-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot37-0--7-0.gif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 02:13:58.327675: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:13:58.327757: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:13:58.328169: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:13:58.328310: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:13:58.328418: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:13:58.328483: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:13:58.328617: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:13:58.328820: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:13:58.328974: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:13:58.329126: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:13:58.329801: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:13:58.329931: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:13:58.330016: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:13:58.330102: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:13:58.330190: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:13:58.330226: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:13:58.359266: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:13:58.359331: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:13:58.359561: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:13:58.359964: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:13:58.360133: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:13:58.360355: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:13:58.360902: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:13:58.361055: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:13:58.378725: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:13:58.378852: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:13:58.380690: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:13:58.380816: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:13:58.381092: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:13:58.381219: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:13:58.382011: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:13:58.382119: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:13:58.384734: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:13:58.384734: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:13:58.384878: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:13:58.384878: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:13:58.390675: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:13:58.390675: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:13:58.390843: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:13:58.390873: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:13:59.009611: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:13:59.013345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6517 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:13:59.020418: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:13:59.020641: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:13:59.022779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6499 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:13:59.023958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6497 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:13:59.038855: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:13:59.040829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6425 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:13:59.076601: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:13:59.077137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5989 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:13:59.085434: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:13:59.085854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5897 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:13:59.109625: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:13:59.110241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5897 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:13:59.127935: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:13:59.129048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5897 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722824039.427933   12392 service.cc:145] XLA service 0x72904c0146a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722824039.428040   12392 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 02:13:59.445494: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 02:13:59.483022: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722824039.495456   12402 service.cc:145] XLA service 0x7290780037b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722824039.495501   12402 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 02:13:59.504179: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722824039.520145   12419 service.cc:145] XLA service 0x72904c014ef0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722824039.520191   12419 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722824039.527486   12486 service.cc:145] XLA service 0x72904c0141c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722824039.527529   12486 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 02:13:59.529204: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 02:13:59.535537: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722824039.542176   12437 service.cc:145] XLA service 0x729054004100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722824039.542222   12437 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722824039.544043   12499 service.cc:145] XLA service 0x729058003430 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722824039.544076   12499 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 02:13:59.546811: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-08-05 02:13:59.550991: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 02:13:59.551338: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 02:13:59.575711: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722824039.578085   12454 service.cc:145] XLA service 0x729054002890 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722824039.578123   12454 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 02:13:59.582424: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-08-05 02:13:59.582495: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722824039.582834   12470 service.cc:145] XLA service 0x729048014140 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722824039.582872   12470 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 02:13:59.586338: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 02:13:59.591227: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1722824039.596162   12392 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-08-05 02:13:59.598723: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-08-05 02:13:59.620432: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:18\u001b[0m 444ms/step/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 02:13:59.634504: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "I0000 00:00:1722824039.654686   12402 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722824039.810396   12419 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722824039.826353   12499 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722824039.827617   12486 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m180/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1722824039.852654   12437 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722824039.853460   12454 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722824039.861267   12470 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot41-0--17-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot41-0--5-0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot41-0--11-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot41-0--7-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot41-0--1-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot41-0--3-0.png/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot41-0--13-0.png\n",
      "\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot41-0--2-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot41-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot41-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot41-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot41-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot41-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot41-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot41-0--2-0.gif/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot41-0--3-0.gif\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7ec5fc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7eff370> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7e97250> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7eb5870> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7e8b2e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7e8f250> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7ea5900> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7ead870> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7eaa950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7e8b2e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7ec8ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7eae8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7ea9900> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7ed0dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7ec1f30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7efb2e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot41-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot41-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot41-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot41-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot41-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot41-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot41-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot41-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot41-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot41-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot41-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot41-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot41-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot41-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot41-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot41-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot41-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot41-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot41-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot41-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot41-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot41-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot41-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot41-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot41-0--13-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot41-0--13-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot41-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot41-0--1-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot41-0--1-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot41-0--5-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot41-0--7-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot41-0--5-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot41-0--7-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot41-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot41-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot41-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot41-0--2-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot41-0--2-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot41-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot41-0--3-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot41-0--3-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot41-0--17-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot41-0--17-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot41-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot41-0--11-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot41-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot41-0--11-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot41-0--11-0.gif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 02:18:54.297556: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:18:54.297624: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:18:54.299316: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:18:54.299450: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:18:54.299981: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:18:54.300169: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:18:54.300196: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:18:54.300325: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:18:54.300456: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:18:54.300541: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:18:54.300639: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:18:54.300695: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:18:54.301121: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:18:54.301291: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:18:54.301371: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:18:54.301502: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:18:54.327909: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:18:54.329187: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:18:54.330322: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:18:54.330859: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:18:54.331067: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:18:54.331636: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:18:54.331879: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:18:54.331995: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:18:54.353126: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:18:54.353254: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:18:54.353847: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:18:54.354014: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:18:54.354193: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:18:54.354314: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:18:54.355259: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:18:54.355384: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:18:54.359569: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:18:54.359727: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:18:54.359762: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:18:54.359932: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:18:54.366266: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:18:54.366266: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:18:54.366449: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:18:54.366468: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:18:54.969188: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:18:54.972483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6737 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:18:54.980339: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:18:54.983684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6609 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:18:55.010602: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:18:55.013827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6417 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:18:55.018566: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:18:55.019285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6417 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:18:55.066406: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:18:55.066460: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:18:55.067075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6061 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:18:55.067082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6063 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:18:55.076444: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:18:55.076782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5897 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:18:55.142058: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:18:55.142850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5801 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722824335.423995   14609 service.cc:145] XLA service 0x729060003d00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722824335.424031   14609 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722824335.427132   14596 service.cc:145] XLA service 0x72904c003d00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722824335.427168   14596 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 02:18:55.431775: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 02:18:55.433821: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722824335.458443   14629 service.cc:145] XLA service 0x72904c003820 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722824335.458481   14629 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 02:18:55.467442: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 02:18:55.467828: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-08-05 02:18:55.473703: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-08-05 02:18:55.518026: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722824335.522875   14643 service.cc:145] XLA service 0x729050015780 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722824335.522929   14643 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722824335.531082   14671 service.cc:145] XLA service 0x72904c015330 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722824335.531117   14671 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 02:18:55.531220: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 02:18:55.537975: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722824335.544820   14688 service.cc:145] XLA service 0x729058003200 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722824335.544868   14688 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 02:18:55.553502: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722824335.567793   14675 service.cc:145] XLA service 0x72904c015320 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722824335.567831   14675 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 02:18:55.570047: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-08-05 02:18:55.575525: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 02:18:55.578498: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722824335.592059   14705 service.cc:145] XLA service 0x729058003f60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722824335.592097   14705 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 02:18:55.600110: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 02:18:55.600867: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-08-05 02:18:55.614854: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:12\u001b[0m 425ms/step/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1722824335.627929   14609 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722824335.631752   14596 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-08-05 02:18:55.646065: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "I0000 00:00:1722824335.646352   14629 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722824335.715118   14671 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722824335.784157   14643 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722824335.821602   14688 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m186/313\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1722824335.840948   14675 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722824335.853582   14705 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot43-0--11-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot43-0--1-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot43-0--2-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot43-0--7-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot43-0--17-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot43-0--5-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot43-0--13-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot43-0--3-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot43-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot43-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot43-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot43-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot43-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot43-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot43-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot43-0--3-0.gif\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7e932e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7ecdfc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7ec9f30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7ea6950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7d03370> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7ead900> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7ec9f30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7eff2e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7ec8ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7ef15a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7efb2e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7d1f370> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7ef9630> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7e38af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7d2b400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7e9a440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot43-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot43-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot43-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot43-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot43-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot43-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot43-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot43-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot43-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot43-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot43-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot43-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot43-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot43-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot43-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot43-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot43-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot43-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot43-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot43-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot43-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot43-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot43-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot43-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot43-0--17-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot43-0--3-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot43-0--17-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot43-0--3-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot43-0--11-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot43-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot43-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot43-0--11-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot43-0--13-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot43-0--13-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot43-0--7-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot43-0--7-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot43-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot43-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot43-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot43-0--1-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot43-0--1-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot43-0--5-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot43-0--5-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot43-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot43-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot43-0--2-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot43-0--2-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot43-0--2-0.gif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 02:23:51.763904: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:23:51.763968: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:23:51.765394: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:23:51.765469: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:23:51.765582: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:23:51.765665: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:23:51.765859: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:23:51.766038: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:23:51.766562: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:23:51.766745: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:23:51.766886: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:23:51.767059: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:23:51.767151: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:23:51.767322: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:23:51.768207: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-08-05 02:23:51.768359: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-08-05 02:23:51.791844: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:23:51.793151: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:23:51.795279: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:23:51.795676: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:23:51.795937: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:23:51.796351: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:23:51.796652: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:23:51.796966: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-08-05 02:23:51.811632: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:23:51.811838: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:23:51.817356: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:23:51.817607: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:23:51.822259: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:23:51.822280: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:23:51.822345: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:23:51.822459: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:23:51.822516: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:23:51.822546: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:23:51.822557: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:23:51.822677: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:23:51.823237: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:23:51.823409: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:23:51.823883: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-08-05 02:23:51.824052: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-08-05 02:23:52.284713: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:23:52.285537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6665 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:23:52.288712: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:23:52.289849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6665 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:23:52.419130: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:23:52.421108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6359 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:23:52.429006: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:23:52.430555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6361 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:23:52.477567: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:23:52.477987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6001 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:23:52.481658: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:23:52.482057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5969 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:23:52.490218: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:23:52.490834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5969 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-08-05 02:23:52.527161: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-08-05 02:23:52.527537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5801 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722824632.785989   16753 service.cc:145] XLA service 0x72904c003d40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722824632.786036   16753 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 02:23:52.794659: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722824632.837532   16723 service.cc:145] XLA service 0x72905c003430 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722824632.837576   16723 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 02:23:52.842147: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-08-05 02:23:52.846160: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 02:23:52.890655: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722824632.911115   16826 service.cc:145] XLA service 0x72904c014a20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722824632.911158   16826 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 02:23:52.920999: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722824632.928117   16889 service.cc:145] XLA service 0x729058003430 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722824632.928151   16889 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722824632.929236   16871 service.cc:145] XLA service 0x729058014ea0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722824632.929279   16871 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 02:23:52.935698: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 02:23:52.937725: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722824632.945457   16812 service.cc:145] XLA service 0x72904c014c60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722824632.945494   16812 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 02:23:52.952836: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722824632.954303   16842 service.cc:145] XLA service 0x729050014380 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722824632.954337   16842 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-08-05 02:23:52.961215: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-05 02:23:52.964819: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-08-05 02:23:52.971209: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-08-05 02:23:52.974051: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-08-05 02:23:52.983711: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 92/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722824632.995678   16859 service.cc:145] XLA service 0x72904c014140 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722824632.995732   16859 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "I0000 00:00:1722824633.001823   16753 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-08-05 02:23:53.003333: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-08-05 02:23:53.004848: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1722824633.010726   16723 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-08-05 02:23:53.038607: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 97/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1722824633.240776   16826 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722824633.245323   16889 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722824633.245339   16871 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722824633.255359   16812 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722824633.266972   16842 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1722824633.272019   16859 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot47-0--5-0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot47-0--2-0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot47-0--13-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot47-0--17-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot47-0--1-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot47-0--7-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot47-0--11-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/circuits/FASHIONMNISTFASHIONMNISTqcnot47-0--3-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot47-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot47-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot47-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot47-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot47-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot47-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot47-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/weights/FASHIONMNISTFASHIONMNISTqcnot47-0--3-0.gif\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7eaa950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7e8f2e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7eccee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7ead900> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7ec5fc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7ee7c70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7d429e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7eaa8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7eff370> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7d3f910> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7eccdc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7d856c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7d1fb50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7d6e0e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7291c7eae950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7291c7ed0ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot47-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot47-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot47-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot47-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot47-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot47-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot47-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_weights/FASHIONMNISTFASHIONMNISTqcnot47-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot47-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot47-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot47-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot47-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot47-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot47-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot47-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/bias/FASHIONMNISTFASHIONMNISTqcnot47-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot47-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot47-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot47-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot47-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot47-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot47-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot47-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_bias/FASHIONMNISTFASHIONMNISTqcnot47-0--17-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot47-0--1-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot47-0--1-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot47-0--7-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot47-0--7-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot47-0--1-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot47-0--2-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot47-0--7-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot47-0--2-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot47-0--3-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot47-0--3-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot47-0--2-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot47-0--3-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot47-0--13-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot47-0--11-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot47-0--13-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot47-0--11-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot47-0--13-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot47-0--11-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot47-0--5-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot47-0--5-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot47-0--5-0.gif\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/individual_samples/FASHIONMNISTFASHIONMNISTqcnot47-0--17-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/relative_samples/FASHIONMNISTFASHIONMNISTqcnot47-0--17-0.png\n",
      "/workspaces/QML-QPF/multiprocessing/output/20240804-171809/visuals/filter/FASHIONMNISTFASHIONMNISTqcnot47-0--17-0.gif\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def pool_job2(detail):\n",
    "    restored_model = Model(*detail)\n",
    "    restored_model.set_data()\n",
    "    #restored_model.prep()\n",
    "    restored_model.prep_qrand_variant(detail[-2],detail[-1])\n",
    "    restored_model.load_history()\n",
    "    restored_model.visuals.circuit()\n",
    "    restored_model.visuals.weights()\n",
    "    restored_model.visuals.relative_weights()\n",
    "    restored_model.visuals.bias()\n",
    "    restored_model.visuals.relative_bias()\n",
    "    restored_model.visuals.data_samples()\n",
    "    restored_model.visuals.relative_samples()\n",
    "    restored_model.visuals.filtering()\n",
    "\n",
    "\n",
    "for cnot_var in cnot_variations:\n",
    "    with ProcessPoolExecutor(8) as executor:\n",
    "        runner = {\n",
    "                executor.submit(pool_job2, (1,2,clock_start,workdir,cnot_var,m)): m for m in ent_variations\n",
    "            }\n",
    "        for future in as_completed(runner):\n",
    "            runner.pop(future) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def UMAP_job(detail):\n",
    "    restored_model = Model(*detail)\n",
    "    restored_model.set_data()\n",
    "    restored_model.prep()\n",
    "    restored_model.load_history()\n",
    "    restored_model.visuals.manifold_umap()\n",
    "\n",
    "for cnot_var in cnot_variations:\n",
    "    {UMAP_job((1,2,clock_start,workdir,cnot_var,m)): m for m in ent_variations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QML-QPF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
