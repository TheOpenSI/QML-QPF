{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-21 17:37:25.122654: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-21 17:37:25.769998: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from datetime import datetime\n",
    "import pathlib\n",
    "import os\n",
    "import gc\n",
    "from core import Model\n",
    "\n",
    "os.environ['CUDA_​DEVICE_​ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "clock_start = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#clock_start = \"20240715-214900\"\n",
    "workdir = str(pathlib.Path().resolve())\n",
    "\n",
    "models =  [\n",
    "    (0,0, clock_start, workdir),\n",
    "    (0,1,clock_start, workdir),\n",
    "    (0,2,clock_start, workdir),\n",
    "    (0,3,clock_start, workdir),\n",
    "    (1,0,clock_start, workdir),\n",
    "    (1,1,clock_start, workdir),\n",
    "    (1,2,clock_start, workdir),\n",
    "    (1,3,clock_start, workdir)\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-21 17:37:27.901312: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-07-21 17:37:27.901398: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-07-21 17:37:27.901791: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-07-21 17:37:27.901856: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-07-21 17:37:27.901959: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-07-21 17:37:27.902123: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-07-21 17:37:27.902499: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-07-21 17:37:27.902671: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-07-21 17:37:27.902948: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-07-21 17:37:27.903129: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-07-21 17:37:27.903680: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-07-21 17:37:27.903695: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-07-21 17:37:27.903867: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-07-21 17:37:27.903868: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-07-21 17:37:27.904587: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-07-21 17:37:27.904806: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-07-21 17:37:27.922514: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-07-21 17:37:27.924135: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-07-21 17:37:27.927628: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-07-21 17:37:27.928467: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-07-21 17:37:27.928910: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-07-21 17:37:27.929166: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-07-21 17:37:27.929418: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-07-21 17:37:27.929918: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-07-21 17:37:27.930428: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-07-21 17:37:27.930585: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-07-21 17:37:27.935772: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-07-21 17:37:27.935911: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-07-21 17:37:27.937067: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-07-21 17:37:27.937233: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-07-21 17:37:27.938000: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-07-21 17:37:27.938145: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-07-21 17:37:27.938502: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-07-21 17:37:27.938651: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-07-21 17:37:27.939174: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-07-21 17:37:27.939306: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-07-21 17:37:27.939599: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-07-21 17:37:27.939760: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-07-21 17:37:27.940670: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-07-21 17:37:27.940831: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-07-21 17:37:28.586874: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-07-21 17:37:28.590877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6703 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-07-21 17:37:28.609854: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-07-21 17:37:28.611205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6411 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-07-21 17:37:28.616977: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-07-21 17:37:28.620309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6409 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-07-21 17:37:28.620802: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-07-21 17:37:28.623638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6391 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-07-21 17:37:28.644216: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-07-21 17:37:28.644615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6145 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-07-21 17:37:28.656744: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-07-21 17:37:28.657131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5961 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-07-21 17:37:28.661542: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-07-21 17:37:28.661923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5929 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "2024-07-21 17:37:28.685538: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:238] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-07-21 17:37:28.686023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6177 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/pennylane/math/utils.py:227: UserWarning: Contains tensors of types {'tensorflow', 'autograd'}; dispatch will prioritize TensorFlow, PyTorch, and  Jax over Autograd. Consider replacing Autograd with vanilla NumPy.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/QML-QPF/lib/python3.10/site-packages/pennylane/math/utils.py:227: UserWarning: Contains tensors of types {'tensorflow', 'autograd'}; dispatch will prioritize TensorFlow, PyTorch, and  Jax over Autograd. Consider replacing Autograd with vanilla NumPy.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 50/118\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721583449.101435   29023 service.cc:145] XLA service 0x7e32c8002700 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1721583449.101485   29023 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721583449.118961   29032 service.cc:145] XLA service 0x7e32e00140a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1721583449.119005   29032 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-07-21 17:37:29.151278: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-07-21 17:37:29.158180: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "I0000 00:00:1721583449.242268   29032 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1721583449.243756   29023 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721583450.696667   29005 service.cc:145] XLA service 0x7e32dc013e70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1721583450.696715   29005 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721583450.722712   29066 service.cc:145] XLA service 0x7e32dc0140b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1721583450.722757   29066 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-07-21 17:37:30.754982: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721583450.777559   28976 service.cc:145] XLA service 0x7e32d4013e70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1721583450.777607   28976 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-07-21 17:37:30.780626: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-21 17:37:30.812184: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-07-21 17:37:30.812240: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-07-21 17:37:30.819310: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-21 17:37:30.912448: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-07-21 17:37:30.913916: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-07-21 17:37:30.915630: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-07-21 17:37:31.025675: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-07-21 17:37:31.025720: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721583451.196640   28981 service.cc:145] XLA service 0x7e32fc013ea0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1721583451.196685   28981 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721583451.230468   29048 service.cc:145] XLA service 0x7e32e4002350 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1721583451.230509   29048 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-07-21 17:37:31.243296: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721583451.257545   28959 service.cc:145] XLA service 0x7e32dc013e70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1721583451.257591   28959 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2024-07-21 17:37:31.276451: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-21 17:37:31.311965: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-21 17:37:31.335879: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-21 17:37:31.372854: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-07-21 17:37:31.398158: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-07-21 17:37:31.441637: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-07-21 17:37:31.556400: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-21 17:37:32.713252: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-07-21 17:37:32.715688: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-07-21 17:37:32.718757: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-07-21 17:37:32.721063: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1364] CUPTI activity buffer flushed\n",
      "2024-07-21 17:37:32.725639: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:540]  GpuTracer has collected 2049 callback api events and 1705 activity events. \n",
      "2024-07-21 17:37:32.730571: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:540]  GpuTracer has collected 2049 callback api events and 1705 activity events. \n",
      "2024-07-21 17:37:32.739904: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-07-21 17:37:32.741346: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: /workspaces/QML-QPF/multiprocessing/output/20240721-173727/runs/MNIST/MNISTno_filter/plugins/profile/2024_07_21_17_37_32/1ba22281c77a.xplane.pb\n",
      "2024-07-21 17:37:32.743612: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-07-21 17:37:32.745048: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: /workspaces/QML-QPF/multiprocessing/output/20240721-173727/runs/FASHIONMNIST/FASHIONMNISTno_filter/plugins/profile/2024_07_21_17_37_32/1ba22281c77a.xplane.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/118\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:46\u001b[0m 5s/stepp"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1721583453.217198   29066 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1721583453.276124   28976 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1721583453.333869   29005 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  5/118\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 197ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1721583453.828900   28959 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1721583453.875210   28981 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1721583453.878891   29048 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 22/118\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 397ms/step118/118 - 11s - 90ms/step - accuracy: 0.7104 - loss: 0.8526 - val_accuracy: 0.7826 - val_loss: 0.6157\n",
      "Epoch 2/30\n",
      "\u001b[1m 23/118\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 398ms/step118/118 - 11s - 95ms/step - accuracy: 0.7059 - loss: 1.0023 - val_accuracy: 0.8657 - val_loss: 0.4992\n",
      "Epoch 2/30\n",
      "\u001b[1m 49/118\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 440ms/step118/118 - 13s - 113ms/step - accuracy: 0.8103 - loss: 0.5488 - val_accuracy: 0.8080 - val_loss: 0.5451\n",
      "Epoch 3/30\n",
      "\u001b[1m 50/118\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 440ms/step118/118 - 13s - 113ms/step - accuracy: 0.8747 - loss: 0.4582 - val_accuracy: 0.8926 - val_loss: 0.3882\n",
      "Epoch 3/30\n",
      "\u001b[1m 82/118\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 433ms/step118/118 - 13s - 114ms/step - accuracy: 0.8284 - loss: 0.4988 - val_accuracy: 0.8191 - val_loss: 0.5146\n",
      "Epoch 4/30\n",
      "\u001b[1m 84/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 429ms/step118/118 - 13s - 114ms/step - accuracy: 0.8902 - loss: 0.3876 - val_accuracy: 0.9005 - val_loss: 0.3481\n",
      "Epoch 4/30\n",
      "\u001b[1m 78/118\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 542ms/step"
     ]
    }
   ],
   "source": [
    "\n",
    "def frontload_data():\n",
    "    from tensorflow import keras\n",
    "    mnist_dataset = keras.datasets.fashion_mnist\n",
    "    (train_images, train_labels), (test_images, test_labels) = mnist_dataset.load_data()\n",
    "    mnist_dataset = keras.datasets.mnist\n",
    "    (train_images, train_labels), (test_images, test_labels) = mnist_dataset.load_data()\n",
    "\n",
    "def pool_job(input):\n",
    "    this_model = Model(*input)\n",
    "    this_model.set_data()\n",
    "    this_model.prep()\n",
    "    this_model.pre_filter()\n",
    "    this_model.fit()\n",
    "    this_model.save_filtered()\n",
    "\n",
    "frontload_data()\n",
    "#to prevent race condition\n",
    "with ProcessPoolExecutor(8) as executor:\n",
    "    runner = {\n",
    "            executor.submit(pool_job, m): m for m in models\n",
    "        }\n",
    "    for future in as_completed(runner):\n",
    "        runner.pop(future)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_job2(detail):\n",
    "    restored_model = Model(*detail)\n",
    "    restored_model.set_data()\n",
    "    restored_model.prep()\n",
    "    restored_model.load_history()\n",
    "    restored_model.visuals.weights()\n",
    "    restored_model.visuals.relative_weights()\n",
    "    restored_model.visuals.bias()\n",
    "    restored_model.visuals.relative_bias()\n",
    "    restored_model.visuals.data_samples()\n",
    "    restored_model.visuals.relative_samples()\n",
    "    restored_model.visuals.filtering()\n",
    "\n",
    "\n",
    "with ProcessPoolExecutor(8) as executor:\n",
    "    runner = {\n",
    "            executor.submit(pool_job2, m): m for m in models\n",
    "        }\n",
    "    for future in as_completed(runner):\n",
    "        runner.pop(future) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UMAP_job(detail):\n",
    "    restored_model = Model(*detail)\n",
    "    restored_model.set_data()\n",
    "    restored_model.prep()\n",
    "    restored_model.load_history()\n",
    "    restored_model.visuals.manifold_umap()\n",
    "\n",
    "{UMAP_job(m): m for m in models}  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QML-QPF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
